{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "cf1_results = pd.read_csv('/content/cf1_results.csv')\n",
    "cf1_results_ltn = pd.read_csv('/content/cf1_results_ltn.csv')\n",
    "\n",
    "# Calculate the last epoch of the normal model\n",
    "last_normal_epoch = cf1_results['Epoch'].max()\n",
    "\n",
    "# Adjust the LTN model epochs to start right after the last epoch of the normal model\n",
    "cf1_results_ltn['Adjusted Epoch'] = cf1_results_ltn['Epoch'] + last_normal_epoch\n",
    "\n",
    "# Group by Epoch and calculate mean accuracy for the normal model\n",
    "avg_cf1_results = cf1_results.groupby('Epoch').agg({'Validation Accuracy': 'mean'}).reset_index()\n",
    "\n",
    "# Find the maximum test accuracy for each fold and speed in the LTN model\n",
    "max_accuracy_per_fold_speed = cf1_results_ltn.groupby(['Fold', 'Speed', 'Adjusted Epoch']).agg({'test_accuracy': 'max'}).reset_index()\n",
    "\n",
    "# Calculate the mean of these maximum accuracies for each adjusted epoch\n",
    "avg_max_accuracy_per_epoch = max_accuracy_per_fold_speed.groupby('Adjusted Epoch').agg({'test_accuracy': 'mean'}).reset_index()\n",
    "\n",
    "# Combine averaged data for a continuous plot\n",
    "combined_avg_results = pd.concat([\n",
    "    avg_cf1_results.rename(columns={'Validation Accuracy': 'Accuracy', 'Epoch': 'Extended Epoch'}),\n",
    "    avg_max_accuracy_per_epoch.rename(columns={'test_accuracy': 'Accuracy', 'Adjusted Epoch': 'Extended Epoch'})\n",
    "])\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.plot(combined_avg_results['Extended Epoch'], combined_avg_results['Accuracy'], label='Average Model Accuracy', marker='o')\n",
    "plt.title('Average Model Accuracy Across Extended Epochs')\n",
    "plt.xlabel('Extended Epoch (Normal + LTN)')\n",
    "plt.ylabel('Average Test Accuracy')\n",
    "plt.axvline(x=last_normal_epoch, color='r', linestyle='--', label='Start of LTN Model')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Standard library imports\n",
    "import argparse\n",
    "import csv\n",
    "import math\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "import csv\n",
    "\n",
    "\n",
    "# Append config directory to sys.path\n",
    "script_dir = os.path.dirname(os.path.abspath(__file__))  # Absolute dir the script is in\n",
    "sys.path.append(os.path.join(script_dir, '..', 'config'))\n",
    "\n",
    "# Third-party library imports\n",
    "import joblib\n",
    "import ltn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from rich.console import Console\n",
    "from rich.table import Table\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "from tensorflow.keras import layers, models, optimizers, callbacks, regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler, ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Input\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
    "from tqdm import tqdm\n",
    "from numpy import mean\n",
    "\n",
    "# Local module imports\n",
    "import config as config\n",
    "from model_creation import LSTMModel, lr_schedule\n",
    "from sequence_generation import load_sequences, save_sequences\n",
    "from model_evaluation import kfold_cross_validation, normalize_importances, permutation_importance_per_class\n",
    "from pgb_data_processing import overview_csv_files, process_pgb_data\n",
    "from data_scaling import load_and_scale_data\n",
    "from util import concatenate_and_delete_ltn_csv_files\n",
    "import commons as commons\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=n_splits, shuffle=False)\n",
    "counter = 0\n",
    "console = Console()\n",
    "processed_bases = set()\n",
    "\n",
    "if os.path.exists(processed_file_tracker):\n",
    "    with open(processed_file_tracker, \"r\") as file:\n",
    "        processed_bases = set(file.read().splitlines())\n",
    "\n",
    "metrics_summary = []\n",
    "\n",
    "for file in sorted(os.listdir(sequences_directory)):\n",
    "    if \"_train_scaled_sequences.npy\" in file:\n",
    "        \n",
    "        if counter >= S:\n",
    "            break\n",
    "        \n",
    "        base_name = file.replace(\"_train_scaled_sequences.npy\", \"\")\n",
    "        if base_name in processed_bases:\n",
    "            continue\n",
    "        processed_bases.add(base_name)\n",
    "        counter+=1\n",
    "        \n",
    "        \n",
    "            \n",
    "            \n",
    "        # Load sequences and labels\n",
    "        train_sequence_file_path = os.path.join(sequences_directory, f\"{base_name}_train_scaled_sequences.npy\")\n",
    "        train_label_file_path = os.path.join(sequences_directory, f\"{base_name}_train_scaled_labels.npy\")\n",
    "        X_train, y_train = load_sequences(train_sequence_file_path, train_label_file_path)\n",
    "        \n",
    "        test_sequence_file_path = os.path.join(sequences_directory, f\"{base_name}_test_scaled_sequences.npy\")\n",
    "        test_label_file_path = os.path.join(sequences_directory, f\"{base_name}_test_scaled_labels.npy\")\n",
    "        X_test, y_test = load_sequences(test_sequence_file_path, test_label_file_path)\n",
    "\n",
    "        # Shuffle the sequences and corresponding labels. Before this they were kept ordered.\n",
    "        train_indices = np.arange(len(X_train))\n",
    "        np.random.shuffle(train_indices)\n",
    "        X_train = X_train[train_indices]\n",
    "        y_train = y_train[train_indices]\n",
    "\n",
    "        test_indices = np.arange(len(X_test))\n",
    "        np.random.shuffle(test_indices)\n",
    "        X_test = X_test[test_indices]\n",
    "        y_test = y_test[test_indices]\n",
    "\n",
    "        # Merge for cross-validation\n",
    "        X = np.concatenate((X_train, X_test), axis=0)\n",
    "        y = np.concatenate((y_train, y_test), axis=0)\n",
    "\n",
    "        input_shape = (sequence_length, num_features)\n",
    "        fold_metrics = []\n",
    "\n",
    "        for fold, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "            metrics_logger = MetricsLogger(results_path, fold_number=fold+1, base_name=base_name)\n",
    "            console.print(f\"[bold green]Training fold {fold + 1}/{n_splits} for {base_name}[/]\")\n",
    "            X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
    "            y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
    "\n",
    "\n",
    "            \n",
    "            # load the model\n",
    "            \n",
    "            model = tf.keras.models.load_model('path_to_saved_model')\n",
    "\n",
    "            \n",
    "            y_val_pred_classes = model.predict(X_val_fold, batch_size = batch_size)\n",
    "            y_val_pred_classes = np.argmax(y_val_pred_classes, axis=1)  # Get predicted classes\n",
    "\n",
    "            # Since y_val_fold contains integer labels, there's no need for conversion\n",
    "            y_val_true_classes = y_val_fold  # Directly use the integer labels\n",
    "\n",
    "            # Calculate and store metrics for this fold\n",
    "            accuracy = accuracy_score(y_val_true_classes, y_val_pred_classes)\n",
    "            precision = precision_score(y_val_true_classes, y_val_pred_classes, average='macro', zero_division=0)\n",
    "            recall = recall_score(y_val_true_classes, y_val_pred_classes, average='macro', zero_division=0)\n",
    "            f1 = f1_score(y_val_true_classes, y_val_pred_classes, average='macro')\n",
    "            fold_metrics.append((accuracy, precision, recall, f1))\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "            console.print(f\"Fold {fold+1} Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n",
    "            \n",
    "            class_importances = permutation_importance_per_class(model, X_val_fold, y_val_fold, n_repeats=4, n_samples=n_samples)\n",
    "            for class_id, importances in class_importances.items():\n",
    "                print(f\"{class_id} Feature Importances:\", importances)\n",
    "            \n",
    "            importances_matrix = np.array(list(class_importances.values()))\n",
    "            # Calculate the average importance across all classes\n",
    "            average_importances = np.mean(importances_matrix, axis=0)\n",
    "            \n",
    "            normalized_average_importances = normalize_importances(average_importances)\n",
    "\n",
    "            print(\"Normalized Average Feature Importances:\", normalized_average_importances)\n",
    "\n",
    "            p = ltn.Predicate.FromLogits(model, activation_function=\"softmax\", with_class_indexing=True)\n",
    "            \n",
    "            @tf.function\n",
    "            def axioms(features, labels, training=False):\n",
    "                x_A = ltn.Variable(\"x_A\", features[labels == 0])\n",
    "                x_B = ltn.Variable(\"x_B\", features[labels == 1])\n",
    "                x_C = ltn.Variable(\"x_C\", features[labels == 2])\n",
    "                x_D = ltn.Variable(\"x_D\", features[labels == 3])\n",
    "                x_E = ltn.Variable(\"x_E\", features[labels == 4])\n",
    "                x_F = ltn.Variable(\"x_F\", features[labels == 5])\n",
    "                x_G = ltn.Variable(\"x_G\", features[labels == 6])\n",
    "                x_H = ltn.Variable(\"x_H\", features[labels == 7])\n",
    "                x_I = ltn.Variable(\"x_I\", features[labels == 8])\n",
    "                axioms = [\n",
    "                    Forall(x_A, p([x_A, class_0], training=training)),\n",
    "                    Forall(x_B, p([x_B, class_1], training=training)),\n",
    "                    Forall(x_C, p([x_C, class_2], training=training)),\n",
    "                    Forall(x_D, p([x_D, class_3], training=training)),\n",
    "                    Forall(x_E, p([x_E, class_4], training=training)),\n",
    "                    Forall(x_F, p([x_F, class_5], training=training)),\n",
    "                    Forall(x_G, p([x_G, class_6], training=training)),\n",
    "                    Forall(x_H, p([x_H, class_7], training=training)),\n",
    "                    Forall(x_I, p([x_I, class_8], training=training))\n",
    "                ]\n",
    "                sat_level = formula_aggregator(axioms).tensor\n",
    "                return sat_level\n",
    "\n",
    "            optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "            \n",
    "            @tf.function\n",
    "            def train_step(features, labels):\n",
    "                # sat and update\n",
    "                with tf.GradientTape() as tape:\n",
    "                    sat = axioms(features, labels, training=True)\n",
    "                    loss = 1.-sat\n",
    "                gradients = tape.gradient(loss, p.trainable_variables)\n",
    "                optimizer.apply_gradients(zip(gradients, p.trainable_variables))\n",
    "                sat = axioms(features, labels) # compute sat without dropout\n",
    "                metrics_dict['train_sat_kb'](sat)\n",
    "                # accuracy\n",
    "                predictions = model([features])\n",
    "                metrics_dict['train_accuracy'](tf.one_hot(labels,9),predictions)\n",
    "                \n",
    "            @tf.function\n",
    "            def test_step(features, labels):\n",
    "                # sat\n",
    "                sat = axioms(features, labels)\n",
    "                metrics_dict['test_sat_kb'](sat)\n",
    "                # accuracy\n",
    "                predictions = model([features])\n",
    "                metrics_dict['test_accuracy'](tf.one_hot(labels,9),predictions)\n",
    "            \n",
    "            \n",
    "            X_train_fold_weighted = X_train_fold * np.array(normalized_average_importances)\n",
    "            X_val_fold_weighted = X_val_fold * np.array(normalized_average_importances)\n",
    "                \n",
    "            ds_train_fold = tf.data.Dataset.from_tensor_slices((X_train_fold_weighted, y_train_fold))\n",
    "            ds_val_fold = tf.data.Dataset.from_tensor_slices((X_val_fold_weighted, y_val_fold))\n",
    "            \n",
    "            ds_train_fold = ds_train_fold.batch(batch_size)\n",
    "            ds_val_fold = ds_val_fold.batch(batch_size)\n",
    "\n",
    "            for batch_features, batch_labels in ds_val_fold:\n",
    "                batch_satisfaction_level = axioms(batch_features, batch_labels, training=False)\n",
    "                print(f\"Batch Satisfaction Level: {batch_satisfaction_level.numpy():.4f}\")\n",
    "                break\n",
    "            \n",
    "\n",
    "            \n",
    "            results_path_ltn_fold = results_path_ltn + base_name +\"_fold\" + str(fold+1) + '_ltn.csv'\n",
    "            commons.train(\n",
    "                epochs,\n",
    "                metrics_dict,\n",
    "                ds_train_fold,\n",
    "                ds_val_fold,\n",
    "                train_step,\n",
    "                test_step,\n",
    "                csv_path=results_path_ltn_fold,\n",
    "                track_metrics=1\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
