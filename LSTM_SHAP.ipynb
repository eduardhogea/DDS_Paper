{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-13 13:18:48.469604: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-13 13:18:48.483187: I external/local_tsl/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-13 13:18:48.608732: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-13 13:18:50.223262: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import tensorflow as tf\n",
    "from joblib import dump, load\n",
    "import ltn\n",
    "import csv\n",
    "import math\n",
    "import wandb\n",
    "\n",
    "\n",
    "dataset_path = '/home/ubuntu/dds_paper/DDS_Paper/data/DDS_Data_SEU'\n",
    "\n",
    "PGB_path = '/home/ubuntu/dds_paper/DDS_Paper/data/DDS_Data_SEU/PGB/PGB'\n",
    "RGB_path = '/home/ubuntu/dds_paper/DDS_Paper/data/DDS_Data_SEU/RGB/RGB'\n",
    "\n",
    "# Specify the CSV file path\n",
    "csv_file = '/home/ubuntu/dds_paper/DDS_Paper/data/data_robust.csv'\n",
    "preprocessor_file = 'preprocessor.joblib'\n",
    "\n",
    "train_path = '/home/ubuntu/dds_paper/DDS_Paper/data/train.csv'\n",
    "val_path = '/home/ubuntu/dds_paper/DDS_Paper/data/val.csv'\n",
    "\n",
    "np.random.seed(45)\n",
    "\n",
    "# Set the chunk size for reading the CSV\n",
    "chunk_size = 100000  # Adjust the chunk size according to your memory limitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Variable_speed Variable_speed: 0file [00:00, ?file/s]\n",
      "Processing Variable_speed Experiment8: 100%|██████████| 9/9 [00:59<00:00,  6.57s/file]\n",
      "Processing Variable_speed Experiment4: 100%|██████████| 9/9 [01:01<00:00,  6.84s/file]\n",
      "Processing Variable_speed Experiment6: 100%|██████████| 9/9 [00:59<00:00,  6.66s/file]\n",
      "Processing Variable_speed Experiment2: 100%|██████████| 9/9 [00:59<00:00,  6.62s/file]\n",
      "Processing Variable_speed Experiment5: 100%|██████████| 9/9 [00:57<00:00,  6.43s/file]\n",
      "Processing Variable_speed Experiment1: 100%|██████████| 9/9 [01:03<00:00,  7.06s/file]\n",
      "Processing Variable_speed Experiment9: 100%|██████████| 9/9 [00:59<00:00,  6.58s/file]\n",
      "Processing Variable_speed Experiment7: 100%|██████████| 9/9 [01:06<00:00,  7.43s/file]\n",
      "Processing Variable_speed Experiment3: 100%|██████████| 9/9 [01:02<00:00,  6.94s/file]\n",
      "Processing Variable_speed Experiment10: 100%|██████████| 9/9 [01:03<00:00,  7.04s/file]\n",
      "Processing 40_0 : 100%|██████████| 9/9 [01:07<00:00,  7.47s/file]\n",
      "Processing 30_4 : 100%|██████████| 9/9 [01:08<00:00,  7.61s/file]\n",
      "Processing 30_3 : 100%|██████████| 9/9 [01:04<00:00,  7.12s/file]\n",
      "Processing 20_0 : 100%|██████████| 9/9 [01:09<00:00,  7.70s/file]\n",
      "Processing 30_5 : 100%|██████████| 9/9 [01:10<00:00,  7.80s/file]\n",
      "Processing 30_2 : 100%|██████████| 9/9 [01:11<00:00,  7.98s/file]\n",
      "Processing 50_0 : 100%|██████████| 9/9 [01:07<00:00,  7.45s/file]\n",
      "Processing 30_0 : 100%|██████████| 9/9 [01:05<00:00,  7.25s/file]\n",
      "Processing 30_1 : 100%|██████████| 9/9 [00:58<00:00,  6.53s/file]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_fault(file_name):\n",
    "    fault_mapping = {\n",
    "        '0Health': 'HEA', '1Chipped': 'CTF', '2Miss': 'MTF', \n",
    "        '3Root': 'RCF', '4Surface': 'SWF', '5Ball': 'BWF', \n",
    "        '6Combination': 'CWF', '7Inner': 'IRF', '8Outer': 'ORF'\n",
    "    }\n",
    "    for key, value in fault_mapping.items():\n",
    "        if key in file_name:\n",
    "            return value\n",
    "    return None\n",
    "\n",
    "def make_csv_writer(csv_file):\n",
    "    csv_writer = csv.writer(csv_file)\n",
    "    csv_writer.writerow(['Channel1', 'Channel2', 'Channel3', 'Channel4', 'Channel5', 'Channel6', 'Channel7', 'Channel8', 'Fault'])\n",
    "    return csv_writer\n",
    "\n",
    "def generate_csv(output_directory, root_path, speed, experiment, files):\n",
    "    if not os.path.exists(output_directory):\n",
    "        os.makedirs(output_directory)\n",
    "    \n",
    "    train_filename_suffix = f\"{speed}_{experiment}_train\" if experiment else f\"{speed}_train\"\n",
    "    test_filename_suffix = f\"{speed}_{experiment}_test\" if experiment else f\"{speed}_test\"\n",
    "    \n",
    "    train_output_file_path = os.path.join(output_directory, f\"PGB_{train_filename_suffix}.csv\")\n",
    "    test_output_file_path = os.path.join(output_directory, f\"PGB_{test_filename_suffix}.csv\")\n",
    "    \n",
    "    with open(train_output_file_path, 'w', newline='', encoding='utf-8') as train_csvfile, \\\n",
    "        open(test_output_file_path, 'w', newline='', encoding='utf-8') as test_csvfile:\n",
    "        train_csv_writer = make_csv_writer(train_csvfile)\n",
    "        test_csv_writer = make_csv_writer(test_csvfile)\n",
    "        \n",
    "        for file in tqdm(files, desc=f\"Processing {speed} {experiment}\", unit=\"file\"):\n",
    "            fault_type = extract_fault(file)\n",
    "            # Only append 'speed' directory for non-variable speed cases\n",
    "            if experiment:\n",
    "                file_path = os.path.join(root_path, file)  # Already includes 'Variable_speed/Experiment#'\n",
    "            else:\n",
    "                file_path = os.path.join(root_path, file)  # 'root_path' already includes 'speed' directory\n",
    "            \n",
    "            data = pd.read_csv(file_path, sep='\\t', header=None, encoding='ISO-8859-1', skiprows=1, nrows=100000)\n",
    "            train_samples, test_samples = data.iloc[:80000, :], data.iloc[80000:100000, :]\n",
    "            \n",
    "            for index, row in train_samples.iterrows():\n",
    "                train_csv_writer.writerow(row[:8].tolist() + [fault_type])\n",
    "            \n",
    "            for index, row in test_samples.iterrows():\n",
    "                test_csv_writer.writerow(row[:8].tolist() + [fault_type])\n",
    "\n",
    "def process_pgb_data(data_root_folder, output_directory):\n",
    "    for root, dirs, files in os.walk(data_root_folder):\n",
    "        parts = root.split(os.sep)\n",
    "        if 'Variable_speed' in parts:\n",
    "            speed = \"Variable_speed\"\n",
    "            experiment_dir = parts[-1]  # Get the last part as the experiment name\n",
    "            exp_files = [f for f in os.listdir(root) if f.endswith('.txt')]\n",
    "            # Pass the 'root' directly without modifying it for variable speed\n",
    "            generate_csv(output_directory, root, speed, experiment_dir, exp_files)\n",
    "        elif 'PGB' in parts and files:\n",
    "            speed = parts[-1]  # Last part of 'root' is the speed directory\n",
    "            # For non-variable speed, pass the 'root' directly\n",
    "            generate_csv(output_directory, root, speed, '', files)\n",
    "\n",
    "data_root_folder = '/home/ubuntu/dds_paper/DDS_Paper/data/DDS_Data_SEU/PGB/PGB'\n",
    "output_directory = '/home/ubuntu/dds_paper/DDS_Paper/data/DDS_Data_SEU/data/csvs'\n",
    "process_pgb_data(data_root_folder, output_directory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted empty file: /home/ubuntu/dds_paper/DDS_Paper/data/DDS_Data_SEU/data/csvs/PGB_Variable_speed_Variable_speed_train.csv\n",
      "Deleted empty file: /home/ubuntu/dds_paper/DDS_Paper/data/DDS_Data_SEU/data/csvs/PGB_Variable_speed_Variable_speed_test.csv\n",
      "                                File Name  Number of Samples   BWF   CTF   CWF   HEA   IRF   MTF   ORF   RCF   SWF\n",
      "                        PGB_20_0_test.csv             180000 20000 20000 20000 20000 20000 20000 20000 20000 20000\n",
      "                       PGB_20_0_train.csv             720000 80000 80000 80000 80000 80000 80000 80000 80000 80000\n",
      "                        PGB_30_0_test.csv             180000 20000 20000 20000 20000 20000 20000 20000 20000 20000\n",
      "                       PGB_30_0_train.csv             720000 80000 80000 80000 80000 80000 80000 80000 80000 80000\n",
      "                        PGB_30_1_test.csv             180000 20000 20000 20000 20000 20000 20000 20000 20000 20000\n",
      "                       PGB_30_1_train.csv             720000 80000 80000 80000 80000 80000 80000 80000 80000 80000\n",
      "                        PGB_30_2_test.csv             180000 20000 20000 20000 20000 20000 20000 20000 20000 20000\n",
      "                       PGB_30_2_train.csv             720000 80000 80000 80000 80000 80000 80000 80000 80000 80000\n",
      "                        PGB_30_3_test.csv             180000 20000 20000 20000 20000 20000 20000 20000 20000 20000\n",
      "                       PGB_30_3_train.csv             720000 80000 80000 80000 80000 80000 80000 80000 80000 80000\n",
      "                        PGB_30_4_test.csv             180000 20000 20000 20000 20000 20000 20000 20000 20000 20000\n",
      "                       PGB_30_4_train.csv             720000 80000 80000 80000 80000 80000 80000 80000 80000 80000\n",
      "                        PGB_30_5_test.csv             180000 20000 20000 20000 20000 20000 20000 20000 20000 20000\n",
      "                       PGB_30_5_train.csv             720000 80000 80000 80000 80000 80000 80000 80000 80000 80000\n",
      "                        PGB_40_0_test.csv             180000 20000 20000 20000 20000 20000 20000 20000 20000 20000\n",
      "                       PGB_40_0_train.csv             720000 80000 80000 80000 80000 80000 80000 80000 80000 80000\n",
      "                        PGB_50_0_test.csv             180000 20000 20000 20000 20000 20000 20000 20000 20000 20000\n",
      "                       PGB_50_0_train.csv             720000 80000 80000 80000 80000 80000 80000 80000 80000 80000\n",
      " PGB_Variable_speed_Experiment10_test.csv             180000 20000 20000 20000 20000 20000 20000 20000 20000 20000\n",
      "PGB_Variable_speed_Experiment10_train.csv             720000 80000 80000 80000 80000 80000 80000 80000 80000 80000\n",
      "  PGB_Variable_speed_Experiment1_test.csv             180000 20000 20000 20000 20000 20000 20000 20000 20000 20000\n",
      " PGB_Variable_speed_Experiment1_train.csv             720000 80000 80000 80000 80000 80000 80000 80000 80000 80000\n",
      "  PGB_Variable_speed_Experiment2_test.csv             180000 20000 20000 20000 20000 20000 20000 20000 20000 20000\n",
      " PGB_Variable_speed_Experiment2_train.csv             720000 80000 80000 80000 80000 80000 80000 80000 80000 80000\n",
      "  PGB_Variable_speed_Experiment3_test.csv             180000 20000 20000 20000 20000 20000 20000 20000 20000 20000\n",
      " PGB_Variable_speed_Experiment3_train.csv             720000 80000 80000 80000 80000 80000 80000 80000 80000 80000\n",
      "  PGB_Variable_speed_Experiment4_test.csv             180000 20000 20000 20000 20000 20000 20000 20000 20000 20000\n",
      " PGB_Variable_speed_Experiment4_train.csv             720000 80000 80000 80000 80000 80000 80000 80000 80000 80000\n",
      "  PGB_Variable_speed_Experiment5_test.csv             180000 20000 20000 20000 20000 20000 20000 20000 20000 20000\n",
      " PGB_Variable_speed_Experiment5_train.csv             720000 80000 80000 80000 80000 80000 80000 80000 80000 80000\n",
      "  PGB_Variable_speed_Experiment6_test.csv             180000 20000 20000 20000 20000 20000 20000 20000 20000 20000\n",
      " PGB_Variable_speed_Experiment6_train.csv             720000 80000 80000 80000 80000 80000 80000 80000 80000 80000\n",
      "  PGB_Variable_speed_Experiment7_test.csv             180000 20000 20000 20000 20000 20000 20000 20000 20000 20000\n",
      " PGB_Variable_speed_Experiment7_train.csv             720000 80000 80000 80000 80000 80000 80000 80000 80000 80000\n",
      "  PGB_Variable_speed_Experiment8_test.csv             180000 20000 20000 20000 20000 20000 20000 20000 20000 20000\n",
      " PGB_Variable_speed_Experiment8_train.csv             720000 80000 80000 80000 80000 80000 80000 80000 80000 80000\n",
      "  PGB_Variable_speed_Experiment9_test.csv             180000 20000 20000 20000 20000 20000 20000 20000 20000 20000\n",
      " PGB_Variable_speed_Experiment9_train.csv             720000 80000 80000 80000 80000 80000 80000 80000 80000 80000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "def overview_csv_files(directory):\n",
    "    data = []\n",
    "    all_faults = set()\n",
    "\n",
    "    for file in os.listdir(directory):\n",
    "        if file.endswith(\".csv\"):\n",
    "            file_path = os.path.join(directory, file)\n",
    "            df = pd.read_csv(file_path)\n",
    "\n",
    "            # Check if the CSV is empty (aside from the header)\n",
    "            if df.shape[0] == 0:\n",
    "                # Delete the empty CSV file\n",
    "                os.remove(file_path)\n",
    "                print(f\"Deleted empty file: {file_path}\")\n",
    "                continue  # Skip further processing for this file\n",
    "\n",
    "            num_samples = len(df)\n",
    "            fault_distribution = Counter(df['Fault'])\n",
    "            all_faults.update(fault_distribution.keys())\n",
    "            data.append({'File Name': file, 'Number of Samples': num_samples, **fault_distribution})\n",
    "\n",
    "    if not data:  # If no data has been gathered, exit the function\n",
    "        print(\"No data found.\")\n",
    "        return\n",
    "\n",
    "    overview_df = pd.DataFrame(data)\n",
    "    for fault in all_faults:\n",
    "        if fault not in overview_df.columns:\n",
    "            overview_df[fault] = 0\n",
    "\n",
    "    cols = ['File Name', 'Number of Samples'] + sorted(all_faults)\n",
    "    overview_df = overview_df[cols]\n",
    "    overview_df.fillna(0, inplace=True)\n",
    "    overview_df.loc[:, 'Number of Samples':] = overview_df.loc[:, 'Number of Samples':].astype(int)\n",
    "\n",
    "    overview_df = overview_df.sort_values(by='File Name')\n",
    "    print(overview_df.to_string(index=False))\n",
    "\n",
    "# Example usage\n",
    "directory = '/home/ubuntu/dds_paper/DDS_Paper/data/DDS_Data_SEU/data/csvs'\n",
    "overview_csv_files(directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import os\n",
    "import joblib  # For saving the scaler model\n",
    "\n",
    "def load_and_scale_data(csv_path, scaler=None, save_scaler_path=None):\n",
    "    \"\"\"\n",
    "    Loads data from a CSV file, scales the features (excluding the 'Fault' column), \n",
    "    and returns the scaled DataFrame. Optionally saves the scaler model.\n",
    "    \"\"\"\n",
    "    # Load the data\n",
    "    data = pd.read_csv(csv_path)\n",
    "    \n",
    "    # Separate features and target\n",
    "    features = data.columns[:-1]  # Assuming the last column is the target\n",
    "    X = data[features]\n",
    "    y = data['Fault']\n",
    "\n",
    "    # Apply scaling\n",
    "    if scaler is None:\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        if save_scaler_path:\n",
    "            joblib.dump(scaler, save_scaler_path)\n",
    "    else:\n",
    "        X_scaled = scaler.transform(X)\n",
    "    \n",
    "    # Combine scaled features with target\n",
    "    scaled_df = pd.DataFrame(X_scaled, columns=features)\n",
    "    scaled_df['Fault'] = y\n",
    "    \n",
    "    return scaled_df\n",
    "\n",
    "# Define your dataset directory\n",
    "dataset_dir = '/home/ubuntu/dds_paper/DDS_Paper/data/DDS_Data_SEU/data/csvs'\n",
    "\n",
    "# Iterate over your dataset files\n",
    "for root, dirs, files in os.walk(dataset_dir):\n",
    "    for file in sorted(files):\n",
    "        if file.endswith('.csv') and not file.endswith('_scaled.csv'):  # Process only unscaled .csv files\n",
    "            csv_path = os.path.join(root, file)\n",
    "            if 'train' in file:\n",
    "                # Handle training data\n",
    "                scaler_path = os.path.join(root, 'scaler_' + file.replace('.csv', '.joblib'))\n",
    "                scaled_train_df = load_and_scale_data(csv_path, save_scaler_path=scaler_path)\n",
    "                # Save the scaled training data\n",
    "                scaled_csv_path = csv_path.replace('.csv', '_scaled.csv')\n",
    "                scaled_train_df.to_csv(scaled_csv_path, index=False)\n",
    "            elif 'test' in file:\n",
    "                # Handle testing data\n",
    "                scaler_path = os.path.join(root, 'scaler_' + file.replace('_test.csv', '_train.joblib'))\n",
    "                scaler = joblib.load(scaler_path) if os.path.exists(scaler_path) else None\n",
    "                scaled_test_df = load_and_scale_data(csv_path, scaler=scaler)\n",
    "                # Save the scaled testing data\n",
    "                scaled_csv_path = csv_path.replace('.csv', '_scaled.csv')\n",
    "                scaled_test_df.to_csv(scaled_csv_path, index=False)\n",
    "\n",
    "            # Delete the original unscaled .csv file\n",
    "            os.remove(csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: PGB_30_4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/ltn/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 100ms/step - accuracy: 0.1825 - loss: 2.2722 - val_accuracy: 0.2158 - val_loss: 4.7243 - learning_rate: 0.1000\n",
      "Epoch 2/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 79ms/step - accuracy: 0.3324 - loss: 1.6752 - val_accuracy: 0.2252 - val_loss: 4.9041 - learning_rate: 0.1000\n",
      "Epoch 3/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.3751 - loss: 1.5864 - val_accuracy: 0.2259 - val_loss: 5.9388 - learning_rate: 0.1000\n",
      "Epoch 4/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.3882 - loss: 1.5582 - val_accuracy: 0.2243 - val_loss: 5.9462 - learning_rate: 0.1000\n",
      "Epoch 5/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.3956 - loss: 1.5448 - val_accuracy: 0.2225 - val_loss: 7.1452 - learning_rate: 0.1000\n",
      "Epoch 6/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.4011 - loss: 1.5347 - val_accuracy: 0.2242 - val_loss: 7.5675 - learning_rate: 0.1000\n",
      "Epoch 7/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 82ms/step - accuracy: 0.4051 - loss: 1.5240 - val_accuracy: 0.2223 - val_loss: 7.9448 - learning_rate: 0.1000\n",
      "Epoch 8/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 82ms/step - accuracy: 0.4071 - loss: 1.5182 - val_accuracy: 0.2232 - val_loss: 7.7565 - learning_rate: 0.1000\n",
      "Epoch 9/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 81ms/step - accuracy: 0.4099 - loss: 1.5141 - val_accuracy: 0.2231 - val_loss: 8.3601 - learning_rate: 0.1000\n",
      "Epoch 10/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.4137 - loss: 1.5077 - val_accuracy: 0.2239 - val_loss: 8.2553 - learning_rate: 0.1000\n",
      "Epoch 11/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.4175 - loss: 1.4985 - val_accuracy: 0.2252 - val_loss: 9.1357 - learning_rate: 0.0100\n",
      "Epoch 12/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.4193 - loss: 1.4939 - val_accuracy: 0.2245 - val_loss: 9.5461 - learning_rate: 0.0100\n",
      "Epoch 13/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.4204 - loss: 1.4914 - val_accuracy: 0.2243 - val_loss: 9.6629 - learning_rate: 0.0100\n",
      "Epoch 14/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 92ms/step - accuracy: 0.4211 - loss: 1.4890 - val_accuracy: 0.2250 - val_loss: 9.8449 - learning_rate: 0.0100\n",
      "Epoch 15/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.4223 - loss: 1.4886 - val_accuracy: 0.2248 - val_loss: 10.5071 - learning_rate: 0.0100\n",
      "Epoch 16/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 81ms/step - accuracy: 0.4216 - loss: 1.4883 - val_accuracy: 0.2260 - val_loss: 10.4100 - learning_rate: 0.0100\n",
      "Epoch 17/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.4213 - loss: 1.4881 - val_accuracy: 0.2240 - val_loss: 10.5514 - learning_rate: 0.0100\n",
      "Epoch 18/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 81ms/step - accuracy: 0.4223 - loss: 1.4853 - val_accuracy: 0.2243 - val_loss: 10.6556 - learning_rate: 0.0100\n",
      "Epoch 19/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.4219 - loss: 1.4872 - val_accuracy: 0.2250 - val_loss: 10.8837 - learning_rate: 0.0100\n",
      "Epoch 20/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.4225 - loss: 1.4844 - val_accuracy: 0.2243 - val_loss: 10.8903 - learning_rate: 0.0100\n",
      "Epoch 21/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 79ms/step - accuracy: 0.4222 - loss: 1.4861 - val_accuracy: 0.2246 - val_loss: 10.9652 - learning_rate: 1.0000e-03\n",
      "Epoch 22/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 82ms/step - accuracy: 0.4218 - loss: 1.4841 - val_accuracy: 0.2244 - val_loss: 10.9756 - learning_rate: 1.0000e-03\n",
      "Epoch 23/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.4238 - loss: 1.4818 - val_accuracy: 0.2247 - val_loss: 11.0176 - learning_rate: 1.0000e-03\n",
      "Epoch 24/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - accuracy: 0.4227 - loss: 1.4845 - val_accuracy: 0.2249 - val_loss: 11.0365 - learning_rate: 1.0000e-03\n",
      "Epoch 25/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.4223 - loss: 1.4856 - val_accuracy: 0.2249 - val_loss: 11.0463 - learning_rate: 1.0000e-03\n",
      "Epoch 26/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.4241 - loss: 1.4824 - val_accuracy: 0.2245 - val_loss: 11.1521 - learning_rate: 1.0000e-03\n",
      "Epoch 27/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.4247 - loss: 1.4820 - val_accuracy: 0.2241 - val_loss: 11.1276 - learning_rate: 1.0000e-03\n",
      "Epoch 28/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.4238 - loss: 1.4825 - val_accuracy: 0.2248 - val_loss: 11.1552 - learning_rate: 1.0000e-03\n",
      "Epoch 29/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 82ms/step - accuracy: 0.4238 - loss: 1.4831 - val_accuracy: 0.2249 - val_loss: 11.2422 - learning_rate: 1.0000e-03\n",
      "Epoch 30/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.4230 - loss: 1.4819 - val_accuracy: 0.2247 - val_loss: 11.2173 - learning_rate: 1.0000e-03\n",
      "Epoch 31/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.4236 - loss: 1.4831 - val_accuracy: 0.2246 - val_loss: 11.2389 - learning_rate: 1.0000e-04\n",
      "Epoch 32/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - accuracy: 0.4233 - loss: 1.4830 - val_accuracy: 0.2247 - val_loss: 11.2542 - learning_rate: 1.0000e-04\n",
      "Epoch 33/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.4234 - loss: 1.4832 - val_accuracy: 0.2247 - val_loss: 11.2617 - learning_rate: 1.0000e-04\n",
      "Epoch 34/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.4229 - loss: 1.4827 - val_accuracy: 0.2247 - val_loss: 11.2723 - learning_rate: 1.0000e-04\n",
      "Epoch 35/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 82ms/step - accuracy: 0.4255 - loss: 1.4793 - val_accuracy: 0.2247 - val_loss: 11.2772 - learning_rate: 1.0000e-04\n",
      "Epoch 36/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.4229 - loss: 1.4835 - val_accuracy: 0.2247 - val_loss: 11.2784 - learning_rate: 1.0000e-04\n",
      "Epoch 37/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.4240 - loss: 1.4821 - val_accuracy: 0.2247 - val_loss: 11.2792 - learning_rate: 1.0000e-04\n",
      "Epoch 38/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.4239 - loss: 1.4824 - val_accuracy: 0.2246 - val_loss: 11.2901 - learning_rate: 1.0000e-04\n",
      "Epoch 39/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.4247 - loss: 1.4827 - val_accuracy: 0.2247 - val_loss: 11.2884 - learning_rate: 1.0000e-04\n",
      "Epoch 40/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.4232 - loss: 1.4819 - val_accuracy: 0.2247 - val_loss: 11.2880 - learning_rate: 1.0000e-04\n",
      "Epoch 41/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.4238 - loss: 1.4828 - val_accuracy: 0.2247 - val_loss: 11.2885 - learning_rate: 1.0000e-05\n",
      "Epoch 42/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 82ms/step - accuracy: 0.4237 - loss: 1.4809 - val_accuracy: 0.2247 - val_loss: 11.2899 - learning_rate: 1.0000e-05\n",
      "Epoch 43/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.4252 - loss: 1.4817 - val_accuracy: 0.2247 - val_loss: 11.2886 - learning_rate: 1.0000e-05\n",
      "Epoch 44/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.4231 - loss: 1.4836 - val_accuracy: 0.2247 - val_loss: 11.2892 - learning_rate: 1.0000e-05\n",
      "Epoch 45/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.4234 - loss: 1.4835 - val_accuracy: 0.2247 - val_loss: 11.2914 - learning_rate: 1.0000e-05\n",
      "Epoch 46/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.4235 - loss: 1.4814 - val_accuracy: 0.2246 - val_loss: 11.2931 - learning_rate: 1.0000e-05\n",
      "Epoch 47/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.4238 - loss: 1.4834 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-05\n",
      "Epoch 48/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 81ms/step - accuracy: 0.4236 - loss: 1.4822 - val_accuracy: 0.2246 - val_loss: 11.2952 - learning_rate: 1.0000e-05\n",
      "Epoch 49/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.4236 - loss: 1.4830 - val_accuracy: 0.2246 - val_loss: 11.2949 - learning_rate: 1.0000e-05\n",
      "Epoch 50/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.4245 - loss: 1.4823 - val_accuracy: 0.2247 - val_loss: 11.2937 - learning_rate: 1.0000e-05\n",
      "Epoch 51/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.4244 - loss: 1.4822 - val_accuracy: 0.2247 - val_loss: 11.2938 - learning_rate: 1.0000e-06\n",
      "Epoch 52/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 79ms/step - accuracy: 0.4237 - loss: 1.4820 - val_accuracy: 0.2247 - val_loss: 11.2939 - learning_rate: 1.0000e-06\n",
      "Epoch 53/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 79ms/step - accuracy: 0.4231 - loss: 1.4821 - val_accuracy: 0.2247 - val_loss: 11.2939 - learning_rate: 1.0000e-06\n",
      "Epoch 54/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.4236 - loss: 1.4820 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-06\n",
      "Epoch 55/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.4232 - loss: 1.4824 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-06\n",
      "Epoch 56/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.4238 - loss: 1.4824 - val_accuracy: 0.2247 - val_loss: 11.2943 - learning_rate: 1.0000e-06\n",
      "Epoch 57/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.4231 - loss: 1.4839 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-06\n",
      "Epoch 58/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.4233 - loss: 1.4826 - val_accuracy: 0.2247 - val_loss: 11.2939 - learning_rate: 1.0000e-06\n",
      "Epoch 59/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.4237 - loss: 1.4814 - val_accuracy: 0.2247 - val_loss: 11.2940 - learning_rate: 1.0000e-06\n",
      "Epoch 60/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.4235 - loss: 1.4848 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-06\n",
      "Epoch 61/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.4230 - loss: 1.4835 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-07\n",
      "Epoch 62/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.4243 - loss: 1.4820 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-07\n",
      "Epoch 63/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.4242 - loss: 1.4826 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-07\n",
      "Epoch 64/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.4229 - loss: 1.4829 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-07\n",
      "Epoch 65/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.4247 - loss: 1.4806 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-07\n",
      "Epoch 66/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 79ms/step - accuracy: 0.4239 - loss: 1.4814 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-07\n",
      "Epoch 67/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - accuracy: 0.4238 - loss: 1.4827 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-07\n",
      "Epoch 68/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.4243 - loss: 1.4823 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-07\n",
      "Epoch 69/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 82ms/step - accuracy: 0.4230 - loss: 1.4827 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-07\n",
      "Epoch 70/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.4236 - loss: 1.4809 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-07\n",
      "Epoch 71/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - accuracy: 0.4243 - loss: 1.4819 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-08\n",
      "Epoch 72/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 82ms/step - accuracy: 0.4238 - loss: 1.4818 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-08\n",
      "Epoch 73/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 90ms/step - accuracy: 0.4250 - loss: 1.4810 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-08\n",
      "Epoch 74/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 89ms/step - accuracy: 0.4243 - loss: 1.4822 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-08\n",
      "Epoch 75/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.4242 - loss: 1.4809 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-08\n",
      "Epoch 76/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 81ms/step - accuracy: 0.4246 - loss: 1.4815 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-08\n",
      "Epoch 77/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.4234 - loss: 1.4839 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-08\n",
      "Epoch 78/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.4232 - loss: 1.4832 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-08\n",
      "Epoch 79/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.4231 - loss: 1.4835 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-08\n",
      "Epoch 80/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 79ms/step - accuracy: 0.4243 - loss: 1.4799 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-08\n",
      "Epoch 81/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 79ms/step - accuracy: 0.4230 - loss: 1.4835 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-09\n",
      "Epoch 82/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 79ms/step - accuracy: 0.4234 - loss: 1.4825 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-09\n",
      "Epoch 83/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - accuracy: 0.4232 - loss: 1.4819 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-09\n",
      "Epoch 84/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.4240 - loss: 1.4830 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-09\n",
      "Epoch 85/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.4229 - loss: 1.4825 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-09\n",
      "Epoch 86/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.4224 - loss: 1.4833 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-09\n",
      "Epoch 87/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.4234 - loss: 1.4836 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-09\n",
      "Epoch 88/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.4240 - loss: 1.4817 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-09\n",
      "Epoch 89/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step - accuracy: 0.4246 - loss: 1.4815 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-09\n",
      "Epoch 90/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.4243 - loss: 1.4808 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-09\n",
      "Epoch 91/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step - accuracy: 0.4239 - loss: 1.4816 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-10\n",
      "Epoch 92/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.4240 - loss: 1.4827 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-10\n",
      "Epoch 93/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 79ms/step - accuracy: 0.4239 - loss: 1.4819 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-10\n",
      "Epoch 94/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.4238 - loss: 1.4827 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-10\n",
      "Epoch 95/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 92ms/step - accuracy: 0.4241 - loss: 1.4824 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-10\n",
      "Epoch 96/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.4229 - loss: 1.4847 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-10\n",
      "Epoch 97/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 93ms/step - accuracy: 0.4235 - loss: 1.4832 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-10\n",
      "Epoch 98/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - accuracy: 0.4228 - loss: 1.4827 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-10\n",
      "Epoch 99/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.4225 - loss: 1.4823 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-10\n",
      "Epoch 100/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 82ms/step - accuracy: 0.4223 - loss: 1.4840 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-10\n",
      "Epoch 101/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.4243 - loss: 1.4819 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-11\n",
      "Epoch 102/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.4244 - loss: 1.4814 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-11\n",
      "Epoch 103/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 79ms/step - accuracy: 0.4246 - loss: 1.4812 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-11\n",
      "Epoch 104/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.4239 - loss: 1.4817 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-11\n",
      "Epoch 105/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.4240 - loss: 1.4829 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-11\n",
      "Epoch 106/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 81ms/step - accuracy: 0.4226 - loss: 1.4824 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-11\n",
      "Epoch 107/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 95ms/step - accuracy: 0.4236 - loss: 1.4818 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-11\n",
      "Epoch 108/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 81ms/step - accuracy: 0.4228 - loss: 1.4828 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-11\n",
      "Epoch 109/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.4239 - loss: 1.4824 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-11\n",
      "Epoch 110/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 91ms/step - accuracy: 0.4234 - loss: 1.4840 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-11\n",
      "Epoch 111/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 81ms/step - accuracy: 0.4253 - loss: 1.4805 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-12\n",
      "Epoch 112/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 81ms/step - accuracy: 0.4238 - loss: 1.4828 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-12\n",
      "Epoch 113/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.4237 - loss: 1.4830 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-12\n",
      "Epoch 114/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 82ms/step - accuracy: 0.4246 - loss: 1.4816 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-12\n",
      "Epoch 115/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.4231 - loss: 1.4835 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-12\n",
      "Epoch 116/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.4238 - loss: 1.4824 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-12\n",
      "Epoch 117/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.4241 - loss: 1.4819 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-12\n",
      "Epoch 118/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.4234 - loss: 1.4835 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-12\n",
      "Epoch 119/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.4233 - loss: 1.4833 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-12\n",
      "Epoch 120/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.4230 - loss: 1.4816 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-12\n",
      "Epoch 121/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.4225 - loss: 1.4837 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-13\n",
      "Epoch 122/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 82ms/step - accuracy: 0.4238 - loss: 1.4816 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-13\n",
      "Epoch 123/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - accuracy: 0.4241 - loss: 1.4820 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-13\n",
      "Epoch 124/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.4235 - loss: 1.4833 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-13\n",
      "Epoch 125/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.4234 - loss: 1.4825 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-13\n",
      "Epoch 126/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.4238 - loss: 1.4818 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-13\n",
      "Epoch 127/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 79ms/step - accuracy: 0.4245 - loss: 1.4827 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-13\n",
      "Epoch 128/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.4233 - loss: 1.4836 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-13\n",
      "Epoch 129/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.4237 - loss: 1.4812 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-13\n",
      "Epoch 130/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.4231 - loss: 1.4831 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-13\n",
      "Epoch 131/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 85ms/step - accuracy: 0.4251 - loss: 1.4801 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-14\n",
      "Epoch 132/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.4232 - loss: 1.4832 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-14\n",
      "Epoch 133/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.4234 - loss: 1.4831 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-14\n",
      "Epoch 134/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.4242 - loss: 1.4814 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-14\n",
      "Epoch 135/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.4237 - loss: 1.4832 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-14\n",
      "Epoch 136/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 79ms/step - accuracy: 0.4238 - loss: 1.4825 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-14\n",
      "Epoch 137/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 81ms/step - accuracy: 0.4233 - loss: 1.4832 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-14\n",
      "Epoch 138/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 79ms/step - accuracy: 0.4254 - loss: 1.4801 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-14\n",
      "Epoch 139/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step - accuracy: 0.4243 - loss: 1.4830 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-14\n",
      "Epoch 140/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.4235 - loss: 1.4818 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-14\n",
      "Epoch 141/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 82ms/step - accuracy: 0.4246 - loss: 1.4823 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-15\n",
      "Epoch 142/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.4245 - loss: 1.4809 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-15\n",
      "Epoch 143/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.4224 - loss: 1.4835 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-15\n",
      "Epoch 144/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.4240 - loss: 1.4830 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-15\n",
      "Epoch 145/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.4219 - loss: 1.4841 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-15\n",
      "Epoch 146/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.4245 - loss: 1.4815 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-15\n",
      "Epoch 147/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - accuracy: 0.4235 - loss: 1.4828 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-15\n",
      "Epoch 148/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.4236 - loss: 1.4834 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-15\n",
      "Epoch 149/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 81ms/step - accuracy: 0.4233 - loss: 1.4831 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-15\n",
      "Epoch 150/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.4232 - loss: 1.4834 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-15\n",
      "Epoch 151/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.4233 - loss: 1.4835 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-16\n",
      "Epoch 152/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.4250 - loss: 1.4801 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-16\n",
      "Epoch 153/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 92ms/step - accuracy: 0.4245 - loss: 1.4818 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-16\n",
      "Epoch 154/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.4241 - loss: 1.4813 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-16\n",
      "Epoch 155/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.4235 - loss: 1.4829 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-16\n",
      "Epoch 156/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 94ms/step - accuracy: 0.4230 - loss: 1.4824 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-16\n",
      "Epoch 157/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.4241 - loss: 1.4826 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-16\n",
      "Epoch 158/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.4226 - loss: 1.4844 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-16\n",
      "Epoch 159/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 81ms/step - accuracy: 0.4237 - loss: 1.4822 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-16\n",
      "Epoch 160/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 82ms/step - accuracy: 0.4237 - loss: 1.4815 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-16\n",
      "Epoch 161/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.4238 - loss: 1.4838 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-17\n",
      "Epoch 162/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.4236 - loss: 1.4826 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-17\n",
      "Epoch 163/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.4238 - loss: 1.4820 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-17\n",
      "Epoch 164/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 89ms/step - accuracy: 0.4242 - loss: 1.4823 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-17\n",
      "Epoch 165/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 87ms/step - accuracy: 0.4234 - loss: 1.4825 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-17\n",
      "Epoch 166/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.4236 - loss: 1.4820 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-17\n",
      "Epoch 167/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.4232 - loss: 1.4843 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-17\n",
      "Epoch 168/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - accuracy: 0.4244 - loss: 1.4819 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-17\n",
      "Epoch 169/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.4242 - loss: 1.4820 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-17\n",
      "Epoch 170/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step - accuracy: 0.4243 - loss: 1.4810 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-17\n",
      "Epoch 171/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.4238 - loss: 1.4815 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-18\n",
      "Epoch 172/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 82ms/step - accuracy: 0.4237 - loss: 1.4817 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-18\n",
      "Epoch 173/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.4229 - loss: 1.4821 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-18\n",
      "Epoch 174/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.4237 - loss: 1.4814 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-18\n",
      "Epoch 175/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 83ms/step - accuracy: 0.4239 - loss: 1.4815 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-18\n",
      "Epoch 176/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 81ms/step - accuracy: 0.4239 - loss: 1.4820 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-18\n",
      "Epoch 177/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 82ms/step - accuracy: 0.4244 - loss: 1.4822 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-18\n",
      "Epoch 178/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 81ms/step - accuracy: 0.4226 - loss: 1.4832 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-18\n",
      "Epoch 179/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 82ms/step - accuracy: 0.4227 - loss: 1.4833 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-18\n",
      "Epoch 180/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 81ms/step - accuracy: 0.4225 - loss: 1.4835 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-18\n",
      "Epoch 181/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 81ms/step - accuracy: 0.4236 - loss: 1.4828 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-19\n",
      "Epoch 182/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.4240 - loss: 1.4809 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-19\n",
      "Epoch 183/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 82ms/step - accuracy: 0.4237 - loss: 1.4825 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-19\n",
      "Epoch 184/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.4231 - loss: 1.4829 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-19\n",
      "Epoch 185/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.4242 - loss: 1.4816 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-19\n",
      "Epoch 186/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.4226 - loss: 1.4825 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-19\n",
      "Epoch 187/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 79ms/step - accuracy: 0.4237 - loss: 1.4837 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-19\n",
      "Epoch 188/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.4227 - loss: 1.4855 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-19\n",
      "Epoch 189/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.4242 - loss: 1.4818 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-19\n",
      "Epoch 190/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.4256 - loss: 1.4798 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-19\n",
      "Epoch 191/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 81ms/step - accuracy: 0.4238 - loss: 1.4824 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-20\n",
      "Epoch 192/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 82ms/step - accuracy: 0.4225 - loss: 1.4829 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-20\n",
      "Epoch 193/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 79ms/step - accuracy: 0.4234 - loss: 1.4826 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-20\n",
      "Epoch 194/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.4240 - loss: 1.4827 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-20\n",
      "Epoch 195/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.4225 - loss: 1.4837 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-20\n",
      "Epoch 196/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.4243 - loss: 1.4836 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-20\n",
      "Epoch 197/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.4239 - loss: 1.4814 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-20\n",
      "Epoch 198/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 90ms/step - accuracy: 0.4238 - loss: 1.4819 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-20\n",
      "Epoch 199/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 81ms/step - accuracy: 0.4240 - loss: 1.4821 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-20\n",
      "Epoch 200/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 87ms/step - accuracy: 0.4228 - loss: 1.4830 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-20\n",
      "Epoch 201/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.4245 - loss: 1.4820 - val_accuracy: 0.2247 - val_loss: 11.2941 - learning_rate: 1.0000e-21\n",
      "Processing: PGB_30_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/envs/ltn/lib/python3.10/site-packages/keras/src/layers/rnn/rnn.py:205: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 97ms/step - accuracy: 0.2209 - loss: 1.9566 - val_accuracy: 0.2333 - val_loss: 7.6980 - learning_rate: 0.1000\n",
      "Epoch 2/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 84ms/step - accuracy: 0.3632 - loss: 1.5742 - val_accuracy: 0.2127 - val_loss: 10.3114 - learning_rate: 0.1000\n",
      "Epoch 3/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.3773 - loss: 1.5405 - val_accuracy: 0.2183 - val_loss: 9.3751 - learning_rate: 0.1000\n",
      "Epoch 4/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.3848 - loss: 1.5273 - val_accuracy: 0.2162 - val_loss: 8.8876 - learning_rate: 0.1000\n",
      "Epoch 5/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.3914 - loss: 1.5189 - val_accuracy: 0.2201 - val_loss: 11.2394 - learning_rate: 0.1000\n",
      "Epoch 6/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.3970 - loss: 1.5125 - val_accuracy: 0.2196 - val_loss: 10.4883 - learning_rate: 0.1000\n",
      "Epoch 7/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.4013 - loss: 1.5059 - val_accuracy: 0.2221 - val_loss: 10.0902 - learning_rate: 0.1000\n",
      "Epoch 8/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.4013 - loss: 1.5042 - val_accuracy: 0.2221 - val_loss: 10.3392 - learning_rate: 0.1000\n",
      "Epoch 9/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.4028 - loss: 1.5021 - val_accuracy: 0.2202 - val_loss: 11.6837 - learning_rate: 0.1000\n",
      "Epoch 10/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 87ms/step - accuracy: 0.4041 - loss: 1.5021 - val_accuracy: 0.2218 - val_loss: 10.9043 - learning_rate: 0.1000\n",
      "Epoch 11/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 79ms/step - accuracy: 0.4089 - loss: 1.4906 - val_accuracy: 0.2200 - val_loss: 10.7598 - learning_rate: 0.0100\n",
      "Epoch 12/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.4115 - loss: 1.4862 - val_accuracy: 0.2196 - val_loss: 11.0728 - learning_rate: 0.0100\n",
      "Epoch 13/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.4130 - loss: 1.4830 - val_accuracy: 0.2194 - val_loss: 11.3030 - learning_rate: 0.0100\n",
      "Epoch 14/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.4137 - loss: 1.4817 - val_accuracy: 0.2201 - val_loss: 11.1742 - learning_rate: 0.0100\n",
      "Epoch 15/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.4138 - loss: 1.4812 - val_accuracy: 0.2195 - val_loss: 11.1580 - learning_rate: 0.0100\n",
      "Epoch 16/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 92ms/step - accuracy: 0.4141 - loss: 1.4805 - val_accuracy: 0.2223 - val_loss: 11.1037 - learning_rate: 0.0100\n",
      "Epoch 17/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.4139 - loss: 1.4803 - val_accuracy: 0.2193 - val_loss: 11.1787 - learning_rate: 0.0100\n",
      "Epoch 18/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.4153 - loss: 1.4792 - val_accuracy: 0.2187 - val_loss: 11.4074 - learning_rate: 0.0100\n",
      "Epoch 19/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.4152 - loss: 1.4774 - val_accuracy: 0.2211 - val_loss: 11.2724 - learning_rate: 0.0100\n",
      "Epoch 20/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 82ms/step - accuracy: 0.4156 - loss: 1.4786 - val_accuracy: 0.2220 - val_loss: 11.2697 - learning_rate: 0.0100\n",
      "Epoch 21/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.4154 - loss: 1.4793 - val_accuracy: 0.2205 - val_loss: 11.4306 - learning_rate: 1.0000e-03\n",
      "Epoch 22/1000\n",
      "\u001b[1m72/72\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 81ms/step - accuracy: 0.4158 - loss: 1.4775 - val_accuracy: 0.2202 - val_loss: 11.4633 - learning_rate: 1.0000e-03\n",
      "Epoch 23/1000\n",
      "\u001b[1m46/72\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 83ms/step - accuracy: 0.4156 - loss: 1.4754"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 88\u001b[0m\n\u001b[1;32m     85\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 88\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# Here, you might want to save the model and any evaluation metrics you care about\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;66;03m# model.save(f'model_{base_name}.h5')\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/ltn/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:118\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    120\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/ltn/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:323\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    322\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 323\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    324\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(\n\u001b[1;32m    325\u001b[0m         step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    326\u001b[0m     )\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/miniconda3/envs/ltn/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/ltn/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/ltn/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/ltn/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ltn/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/ltn/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/ltn/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/ltn/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/envs/ltn/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "def lr_schedule(epoch, lr):\n",
    "    \"\"\"Learning rate schedule function.\n",
    "    \n",
    "    Decreases the learning rate by a factor of 0.1 every 10 epochs.\n",
    "    \"\"\"\n",
    "    if epoch % 10 == 0 and epoch > 0:\n",
    "        return lr * 0.1\n",
    "    return lr\n",
    "\n",
    "# Directory containing your scaled CSV files\n",
    "csv_directory = '/home/ubuntu/dds_paper/DDS_Paper/data/DDS_Data_SEU/data/csvs'\n",
    "\n",
    "def load_data(train_path, test_path):\n",
    "    # Load datasets\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "\n",
    "    # Split into features and labels\n",
    "    X_train, y_train = train_df.iloc[:, :-1], train_df.iloc[:, -1]\n",
    "    X_test, y_test = test_df.iloc[:, :-1], test_df.iloc[:, -1]\n",
    "\n",
    "    # Encode labels\n",
    "    encoder = LabelEncoder()\n",
    "    y_train_encoded = encoder.fit_transform(y_train)\n",
    "    y_test_encoded = encoder.transform(y_test)\n",
    "\n",
    "    y_train_onehot = to_categorical(y_train_encoded)\n",
    "    y_test_onehot = to_categorical(y_test_encoded)\n",
    "\n",
    "    # Reshape for LSTM [samples, timesteps, features]\n",
    "    X_train = X_train.values.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "    X_test = X_test.values.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "    return X_train, y_train_onehot, X_test, y_test_onehot\n",
    "\n",
    "def create_model(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        LSTM(100, return_sequences=True, input_shape=input_shape),\n",
    "        Dropout(0.2),\n",
    "        LSTM(100, return_sequences=True),\n",
    "        Dropout(0.2),\n",
    "        LSTM(100),\n",
    "        Dropout(0.2),\n",
    "        Dense(100, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Compile model with the initial learning rate\n",
    "    model.compile(optimizer=Adam(learning_rate=0.1), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Iterate through the directory to find matching scaled train and test pairs\n",
    "for file in os.listdir(csv_directory):\n",
    "    if file.endswith(\"_train_scaled.csv\"):\n",
    "        base_name = file.replace(\"_train_scaled.csv\", \"\")\n",
    "        test_file = base_name + \"_test_scaled.csv\"\n",
    "\n",
    "        if test_file in os.listdir(csv_directory):\n",
    "            train_path = os.path.join(csv_directory, file)\n",
    "            test_path = os.path.join(csv_directory, test_file)\n",
    "\n",
    "            print(f\"Processing: {base_name}\")\n",
    "            X_train, y_train, X_test, y_test = load_data(train_path, test_path)\n",
    "\n",
    "            # Create model\n",
    "            model = create_model(input_shape=(X_train.shape[1], X_train.shape[2]), num_classes=y_train.shape[1])\n",
    "            # Create an instance of the LearningRateScheduler callback\n",
    "            lr_scheduler = LearningRateScheduler(lr_schedule, verbose=0)\n",
    "            # Early stopping to avoid overfitting\n",
    "            early_stopping = EarlyStopping(monitor='val_loss', patience=200, restore_best_weights=True)\n",
    "\n",
    "            # Train the model\n",
    "            model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=1000, batch_size=10000, callbacks=[early_stopping, lr_scheduler], verbose=1)\n",
    "\n",
    "            # Here, you might want to save the model and any evaluation metrics you care about\n",
    "            # model.save(f'model_{base_name}.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ltn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
