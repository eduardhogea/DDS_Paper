{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-12 07:09:23.487110: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-12 07:09:23.563993: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-12 07:09:23.567461: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-12 07:09:25.216411: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33meduard-hogea00\u001b[0m (\u001b[33mdds-paper\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/dds_paper/DDS_Paper/wandb/run-20230912_070928-rzxdnos6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dds-paper/LCNC/runs/rzxdnos6' target=\"_blank\">CNN_backbone</a></strong> to <a href='https://wandb.ai/dds-paper/LCNC' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dds-paper/LCNC' target=\"_blank\">https://wandb.ai/dds-paper/LCNC</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dds-paper/LCNC/runs/rzxdnos6' target=\"_blank\">https://wandb.ai/dds-paper/LCNC/runs/rzxdnos6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import tensorflow as tf\n",
    "from joblib import dump, load\n",
    "import ltn\n",
    "import csv\n",
    "import math\n",
    "import wandb\n",
    "\n",
    "WANDB_START_METHOD=\"thread\"\n",
    "wandb.init(project=\"LCNC\", name=\"CNN_backbone\")\n",
    "\n",
    "\n",
    "dataset_path = '/home/ubuntu/dds_paper/DDS_Paper/data/DDS_Data_SEU'\n",
    "\n",
    "PGB_path = '/home/ubuntu/dds_paper/DDS_Paper/data/DDS_Data_SEU/PGB'\n",
    "RGB_path = '/home/ubuntu/dds_paper/DDS_Paper/data/DDS_Data_SEU/RGB'\n",
    "\n",
    "# Specify the CSV file path\n",
    "csv_file = '/home/ubuntu/dds_paper/DDS_Paper/data/data_robust.csv'\n",
    "preprocessor_file = 'preprocessor.joblib'\n",
    "\n",
    "train_path = '/home/ubuntu/dds_paper/DDS_Paper/data/train.csv'\n",
    "val_path = '/home/ubuntu/dds_paper/DDS_Paper/data/val.csv'\n",
    "\n",
    "np.random.seed(45)\n",
    "\n",
    "# Set the chunk size for reading the CSV\n",
    "chunk_size = 100000  # Adjust the chunk size according to your memory limitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fault(file_name):\n",
    "    match = re.search(r'\\d+', file_name)\n",
    "    if match:\n",
    "        return int(match.group(0)[0])  # Extract the first digit\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def process_files_to_csv(data_folders, output_file):\n",
    "    # Check if the file already exists\n",
    "    if os.path.isfile(output_file):\n",
    "        print(f\"File {output_file} already exists. Skipping processing.\")\n",
    "        return\n",
    "\n",
    "    total_files = sum([len(files) for data_folder in data_folders for r, d, files in os.walk(data_folder)])\n",
    "\n",
    "    with open(output_file, 'w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerow(['Channel1', 'Channel2', 'Channel3', 'Channel4', 'Channel5', 'Channel6', 'Channel7', 'Channel8', 'Speed', 'Type', 'Fault'])\n",
    "\n",
    "        with tqdm(total=total_files, desc=\"Processing files\", unit=\"file\") as pbar:\n",
    "            for data_folder in data_folders:\n",
    "                for root, dirs, files in os.walk(data_folder):\n",
    "                    if '.ipynb_checkpoints' in root:\n",
    "                        continue  # Skip .ipynb_checkpoints folders\n",
    "                    for file in files:\n",
    "                        if file.endswith('.txt'):\n",
    "                            file_path = os.path.join(root, file)\n",
    "                            path_parts = file_path.split('\\\\')\n",
    "                            variable_speed = 'Variable_speed' in file_path\n",
    "                            type_index = -4 if variable_speed else -3\n",
    "                            type = path_parts[type_index] if path_parts[type_index] in ['PGB', 'RGB'] else None\n",
    "                            if type is not None:\n",
    "                                speed_index = -3 if variable_speed else -2\n",
    "                                speed = path_parts[speed_index]\n",
    "                                fault = extract_fault(file)\n",
    "\n",
    "                                data = pd.read_csv(file_path, sep='\\t', encoding='ISO-8859-1')\n",
    "                                reshaped_data = data.values[:, :]\n",
    "\n",
    "                                for row_data in tqdm(reshaped_data, desc=\"Processing rows\", unit=\"row\", leave=False):\n",
    "                                    row = row_data.tolist() + [speed, type, fault]\n",
    "                                    csv_writer.writerow(row)\n",
    "                            pbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /home/ubuntu/dds_paper/DDS_Paper/data/data_robust.csv already exists. Skipping processing.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "process_files_to_csv([PGB_path, RGB_path], csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files /home/ubuntu/dds_paper/DDS_Paper/data/train.csv and /home/ubuntu/dds_paper/DDS_Paper/data/val.csv already exist. Skipping processing.\n"
     ]
    }
   ],
   "source": [
    "def split_and_sample_data(file_path, output_train, output_val, train_ratio=0.8, sample_fraction=0.01):\n",
    "    # Check if the output files already exist\n",
    "    if os.path.isfile(output_train) and os.path.isfile(output_val):\n",
    "        print(f\"Files {output_train} and {output_val} already exist. Skipping processing.\")\n",
    "        return\n",
    "    \n",
    "    chunksize = 100000\n",
    "    total_lines = sum([80740352, 80740352, 80740352, 80740352, 80740352, 80740352, 80740352, 80740352, 80740352])\n",
    "    total_chunks = math.ceil(total_lines / chunksize)\n",
    "\n",
    "    reader = pd.read_csv(file_path, chunksize=chunksize)\n",
    "\n",
    "    with open(output_train, 'w', newline='') as train_file, open(output_val, 'w', newline='') as val_file:\n",
    "        train_writer = csv.writer(train_file)\n",
    "        val_writer = csv.writer(val_file)\n",
    "        \n",
    "        for i, chunk in tqdm(enumerate(reader), total=total_chunks, desc=\"Processing chunks\", unit=\"chunk\"):\n",
    "            chunk_sample = chunk.sample(frac=sample_fraction, random_state=1)\n",
    "            if i == 0:\n",
    "                train_writer.writerow(chunk_sample.columns.values)\n",
    "                val_writer.writerow(chunk_sample.columns.values)\n",
    "\n",
    "            train_data = chunk_sample.iloc[:int(train_ratio*len(chunk_sample))].values\n",
    "            val_data = chunk_sample.iloc[int(train_ratio*len(chunk_sample)):].values\n",
    "\n",
    "            train_writer.writerows(train_data)\n",
    "            val_writer.writerows(val_data)\n",
    "\n",
    "split_and_sample_data(csv_file, train_path, val_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing CSV: 59chunk [00:06,  9.02chunk/s]                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fault: 0, Count: 645879\n",
      "Fault: 1, Count: 645871\n",
      "Fault: 2, Count: 645949\n",
      "Fault: 3, Count: 645932\n",
      "Fault: 4, Count: 645904\n",
      "Fault: 5, Count: 645920\n",
      "Fault: 7, Count: 645943\n",
      "Fault: 6, Count: 646001\n",
      "Fault: 8, Count: 645906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize a dictionary to store the fault counts\n",
    "fault_counts = {}\n",
    "\n",
    "# Iterate through the CSV file using chunksize\n",
    "with tqdm(total=1, unit='chunk', desc='Processing CSV') as pbar:\n",
    "    for chunk in pd.read_csv(train_path, chunksize=chunk_size):\n",
    "        \n",
    "        #print(chunk)\n",
    "        # Assuming there is a column named 'fault' in the CSV representing the fault type\n",
    "        fault_column = 'Fault'\n",
    "\n",
    "        # Count the occurrences of each fault in the current chunk\n",
    "        fault_chunk_counts = chunk[fault_column].value_counts()\n",
    "\n",
    "        # Aggregate the counts with the overall fault_counts dictionary\n",
    "        for fault, count in fault_chunk_counts.items():\n",
    "            fault_counts[fault] = fault_counts.get(fault, 0) + count\n",
    "\n",
    "        pbar.update()\n",
    "\n",
    "# Print the fault counts\n",
    "for fault, count in fault_counts.items():\n",
    "    print(f\"Fault: {fault}, Count: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing CSV: 59chunk [00:07,  7.72chunk/s]                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed Counts:\n",
      "Speed: 20_0, Count: 604001\n",
      "Speed: 30_0, Count: 603957\n",
      "Speed: 30_1, Count: 604001\n",
      "Speed: 30_2, Count: 603954\n",
      "Speed: 30_3, Count: 604010\n",
      "Speed: 30_4, Count: 603944\n",
      "Speed: 30_5, Count: 604010\n",
      "Speed: 40_0, Count: 603952\n",
      "Speed: 50_0, Count: 603999\n",
      "Speed: Variable_speed, Count: 377477\n",
      "Type Counts:\n",
      "Type: PGB, Count: 2906670\n",
      "Type: RGB, Count: 2906635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize dictionaries to store the counts\n",
    "speed_counts = {}\n",
    "type_counts = {}\n",
    "\n",
    "# Iterate through the CSV file using chunksize\n",
    "with tqdm(total=1, unit='chunk', desc='Processing CSV') as pbar:\n",
    "    for chunk in pd.read_csv(train_path, chunksize=chunk_size):\n",
    "        # Assuming there is a column named 'Speed' in the CSV representing the speed values\n",
    "        \n",
    "        speed_column = 'Speed'\n",
    "\n",
    "        # Count the occurrences of each speed value in the current chunk\n",
    "        speed_chunk_counts = chunk[speed_column].value_counts()\n",
    "\n",
    "        # Aggregate the counts with the overall speed_counts dictionary\n",
    "        for speed, count in speed_chunk_counts.items():\n",
    "            speed_counts[speed] = speed_counts.get(speed, 0) + count\n",
    "\n",
    "        # Assuming there is a column named 'Type' in the CSV representing the types\n",
    "        type_column = 'Type'\n",
    "\n",
    "        # Count the occurrences of each type in the current chunk\n",
    "        type_chunk_counts = chunk[type_column].value_counts()\n",
    "\n",
    "        # Aggregate the counts with the overall type_counts dictionary\n",
    "        for typ, count in type_chunk_counts.items():\n",
    "            type_counts[typ] = type_counts.get(typ, 0) + count\n",
    "\n",
    "        pbar.update()\n",
    "\n",
    "# Print the speed counts\n",
    "print(\"Speed Counts:\")\n",
    "for speed, count in speed_counts.items():\n",
    "    print(f\"Speed: {speed}, Count: {count}\")\n",
    "\n",
    "# Print the type counts\n",
    "print(\"Type Counts:\")\n",
    "for typ, count in type_counts.items():\n",
    "    print(f\"Type: {typ}, Count: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(batch_size, data = csv_file):\n",
    "    chunksize = batch_size\n",
    "    for chunk in pd.read_csv(data, chunksize=chunksize):\n",
    "        # One-hot encode the categorical features\n",
    "        categorical_features = chunk[categorical_features_columns]\n",
    "        categorical_features = one_hot_encoder.transform(categorical_features).toarray()\n",
    "        \n",
    "        # Concatenate with numerical features\n",
    "        numerical_features = chunk[numerical_features_columns]\n",
    "        X = np.concatenate([numerical_features, categorical_features], axis=1)\n",
    "\n",
    "        sample_size = X.shape[0]\n",
    "        #print(sample_size)\n",
    "        time_steps = X.shape[1]\n",
    "        #print(time_steps)\n",
    "        input_dimensions = 1\n",
    "\n",
    "        X_reshaped = X.reshape(sample_size,time_steps,input_dimensions)\n",
    "\n",
    "        # Extract the labels\n",
    "        y = chunk['Fault'].values\n",
    "\n",
    "        yield X_reshaped, y\n",
    "\n",
    "def data_generator_all(batch_size, data = csv_file):\n",
    "    # Read all the data\n",
    "    df = pd.read_csv(data)\n",
    "    \n",
    "    # Shuffle the DataFrame rows \n",
    "    df = df.sample(frac=1)\n",
    "\n",
    "    # Calculate the number of batches\n",
    "    num_batches = len(df) // batch_size\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        batch = df.iloc[i*batch_size:(i+1)*batch_size]\n",
    "\n",
    "        # One-hot encode the categorical features\n",
    "        categorical_features = batch[categorical_features_columns]\n",
    "        categorical_features = one_hot_encoder.transform(categorical_features).toarray()\n",
    "\n",
    "        # Concatenate with numerical features\n",
    "        numerical_features = batch[numerical_features_columns].values\n",
    "        X = np.concatenate([numerical_features, categorical_features], axis=1)\n",
    "\n",
    "        sample_size = X.shape[0]\n",
    "        time_steps = X.shape[1]\n",
    "        input_dimensions = 1\n",
    "\n",
    "        X_reshaped = X.reshape(sample_size, time_steps, input_dimensions)\n",
    "\n",
    "        # Extract the labels\n",
    "        y = batch['Fault'].values\n",
    "\n",
    "        yield X_reshaped, y\n",
    "\n",
    "\n",
    "# Define the categories\n",
    "# Define the categories\n",
    "speed_categories = ['20_0','30_0','30_1','30_2', '30_3','30_4','30_5','40_0','50_0', 'Variable_speed']\n",
    "type_categories = ['PGB', 'RGB']\n",
    "\n",
    "# Initialize the OneHotEncoder\n",
    "one_hot_encoder = OneHotEncoder(categories=[speed_categories, type_categories])\n",
    "\n",
    "# Create a dummy dataset\n",
    "dummy_df = pd.DataFrame(data=[['20_0', 'PGB']], columns=['Speed', 'Type'])\n",
    "\n",
    "# Fit the encoder\n",
    "one_hot_encoder.fit(dummy_df)\n",
    "\n",
    "# Define your feature column names\n",
    "categorical_features_columns = ['Speed', 'Type']\n",
    "numerical_features_columns = ['Channel1', 'Channel2', 'Channel3', 'Channel4', 'Channel5', 'Channel6', 'Channel7', 'Channel8']\n",
    "\n",
    "# batch_size = 2  # Adjust as necessary\n",
    "# dataset = tf.data.Dataset.from_generator(data_generator, args=[batch_size], output_signature=(\n",
    "#     tf.TensorSpec(shape=(batch_size, 1, 20), dtype=tf.float32),  # Update this to match the shape of X\n",
    "#     tf.TensorSpec(shape=(batch_size,), dtype=tf.int32)\n",
    "# ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 20, 1)\n",
      "[[[-1.63977e-01]\n",
      "  [-7.50700e-03]\n",
      "  [ 5.11600e-03]\n",
      "  ...\n",
      "  [ 0.00000e+00]\n",
      "  [ 0.00000e+00]\n",
      "  [ 1.00000e+00]]\n",
      "\n",
      " [[-2.02326e-01]\n",
      "  [-4.72200e-03]\n",
      "  [ 1.15180e-02]\n",
      "  ...\n",
      "  [ 0.00000e+00]\n",
      "  [ 0.00000e+00]\n",
      "  [ 1.00000e+00]]\n",
      "\n",
      " [[-1.13385e-01]\n",
      "  [-3.02100e-03]\n",
      "  [ 2.12600e-03]\n",
      "  ...\n",
      "  [ 0.00000e+00]\n",
      "  [ 1.00000e+00]\n",
      "  [ 0.00000e+00]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-1.39151e-01]\n",
      "  [-1.02660e-02]\n",
      "  [-3.91800e-03]\n",
      "  ...\n",
      "  [ 0.00000e+00]\n",
      "  [ 1.00000e+00]\n",
      "  [ 0.00000e+00]]\n",
      "\n",
      " [[-1.17069e-01]\n",
      "  [ 4.91500e-03]\n",
      "  [ 1.49870e-02]\n",
      "  ...\n",
      "  [ 0.00000e+00]\n",
      "  [ 1.00000e+00]\n",
      "  [ 0.00000e+00]]\n",
      "\n",
      " [[-1.29793e-01]\n",
      "  [ 6.57000e-04]\n",
      "  [-7.79900e-03]\n",
      "  ...\n",
      "  [ 0.00000e+00]\n",
      "  [ 0.00000e+00]\n",
      "  [ 1.00000e+00]]]\n",
      "[5 1 7 6 1 1 7 1 0 7 0 8 2 4 1 4 3 8 1 2 7 0 2 0 6 5 4 8 3 5 8 3 2 4 6 8 1\n",
      " 5 3 7 1 1 1 3 0 6 8 0 3 6 3 7 1 2 7 0 7 3 3 6 7 8 0 7 5 8 3 4 8 4 1 2 5 3\n",
      " 4 3 4 4 4 5 2 4 8 6 0 7 0 5 8 2 4 5 4 3 6 3 8 4 2 3 6 2 3 4 2 8 4 6 1 0 7\n",
      " 2 0 1 5 2 0 4 5 4 6 0 2 7 4 0 0 5 4 8 5 1 2 8 4 5 2 3 4 8 7 6 6 7 4 1 2 0\n",
      " 0 1 6 6 8 5 2 1 2 0 5 5 8 2 7 3 1 8 1 0 6 4 2 6 8 7 1 4 5 7 8 2 4 6 2 6 6\n",
      " 0 4 3 4 6 4 3 6 3 3 1 4 3 4 3 2 5 6 2 2 1 6 7 5 5 7 0 4 1 2 3 3 0 8 5 5 4\n",
      " 8 3 2 2 1 7 6 5 4 7 6 5 5 8 1 2 3 7 3 0 0 6 1 1 1 1 4 4 7 7 2 1 3 4]\n"
     ]
    }
   ],
   "source": [
    "generator = data_generator_all(batch_size=256, data = train_path)\n",
    "last_X, last_y = None, None\n",
    "\n",
    "for sample_X, sample_y in generator:\n",
    "    last_X, last_y = sample_X, sample_y\n",
    "    print(last_X.shape)\n",
    "    break\n",
    "\n",
    "print(last_X)\n",
    "print(last_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN as backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "def build_cnn_backbone():\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Input(shape=(last_X.shape[1],last_X.shape[2])))\n",
    "    model.add(keras.layers.Conv1D(filters=64, kernel_size=4, activation='elu', name=\"Conv1D_1\"))\n",
    "    model.add(keras.layers.Dropout(0.5))\n",
    "    model.add(keras.layers.Conv1D(filters=32, kernel_size=3, activation='elu', name=\"Conv1D_2\"))\n",
    "    model.add(keras.layers.Conv1D(filters=16, kernel_size=2, activation='elu', name=\"Conv1D_3\"))\n",
    "    model.add(keras.layers.MaxPooling1D(pool_size=2, name=\"MaxPooling1D\"))\n",
    "    model.add(keras.layers.Flatten())\n",
    "    #model.add(keras.layers.Dense(8, activation='relu', name=\"Dense_1\"))\n",
    "    model.add(keras.layers.Dense(9, name=\"Dense_2\"))\n",
    "    return model\n",
    "\n",
    "# Build the CNN backbone model\n",
    "model = build_cnn_backbone()\n",
    "\n",
    "# Wrap the model in an LTN predicate\n",
    "p = ltn.Predicate.FromLogits(model, activation_function=\"softmax\", with_class_indexing=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants to index/iterate on the classes\n",
    "HEALTHY = ltn.Constant(0, trainable=False)\n",
    "CTF = ltn.Constant(1, trainable=False)\n",
    "MTF = ltn.Constant(2, trainable=False)\n",
    "RCF = ltn.Constant(3, trainable=False)\n",
    "SWF = ltn.Constant(4, trainable=False)\n",
    "BWF = ltn.Constant(5, trainable=False)\n",
    "CWF = ltn.Constant(6, trainable=False)\n",
    "IRF = ltn.Constant(7, trainable=False)\n",
    "ORF = ltn.Constant(8, trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#operators\n",
    "Not = ltn.Wrapper_Connective(ltn.fuzzy_ops.Not_Std())\n",
    "And = ltn.Wrapper_Connective(ltn.fuzzy_ops.And_Prod())\n",
    "Or = ltn.Wrapper_Connective(ltn.fuzzy_ops.Or_ProbSum())\n",
    "Implies = ltn.Wrapper_Connective(ltn.fuzzy_ops.Implies_Reichenbach())\n",
    "Forall = ltn.Wrapper_Quantifier(ltn.fuzzy_ops.Aggreg_pMeanError(p=2),semantics=\"forall\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the formula aggregator\n",
    "formula_aggregator = ltn.Wrapper_Formula_Aggregator(ltn.fuzzy_ops.Aggreg_pMeanError(p=2))\n",
    "\n",
    "@tf.function\n",
    "def axioms(features, labels, training=False):\n",
    "    # Variables for each class\n",
    "    x_healthy = ltn.Variable(\"x_healthy\", features[labels == 0])\n",
    "    x_ctf = ltn.Variable(\"x_ctf\", features[labels == 1])\n",
    "    x_mtf = ltn.Variable(\"x_mtf\", features[labels == 2])\n",
    "    x_rcf = ltn.Variable(\"x_rcf\", features[labels == 3])\n",
    "    x_swf = ltn.Variable(\"x_swf\", features[labels == 4])\n",
    "    x_bwf = ltn.Variable(\"x_bwf\", features[labels == 5])\n",
    "    x_cwf = ltn.Variable(\"x_cwf\", features[labels == 6])\n",
    "    x_irf = ltn.Variable(\"x_irf\", features[labels == 7])\n",
    "    x_orf = ltn.Variable(\"x_orf\", features[labels == 8])\n",
    "\n",
    "    # Fault list for mutual exclusivity axioms\n",
    "    faults = [HEALTHY, CTF, MTF, RCF, SWF, BWF, CWF, IRF, ORF]\n",
    "    fault_vars = [x_healthy, x_ctf, x_mtf, x_rcf, x_swf, x_bwf, x_cwf, x_irf, x_orf]\n",
    "\n",
    "    axioms = []\n",
    "    for i, fault in enumerate(faults):\n",
    "        # Add the axiom that for all x of a certain fault, the probability of that fault should be high\n",
    "        axioms.append(Forall(fault_vars[i], p([fault_vars[i], fault], training=training)))\n",
    "\n",
    "        # Add the axioms for mutual exclusivity\n",
    "        for j, other_fault in enumerate(faults):\n",
    "            if i != j:\n",
    "                axioms.append(Forall(fault_vars[i], Not(p([fault_vars[i], other_fault], training=training))))\n",
    "\n",
    "    sat_level = formula_aggregator(axioms).tensor\n",
    "    return sat_level\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial sat level 0.68548\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print the initial satisfaction level for each batch of the test dataset\n",
    "for sample_X, sample_y in generator:\n",
    "    #sample_X_reshaped = tf.reshape(sample_X, (sample_X.shape[0], sample_X.shape[1], 1))\n",
    "    #print(sample_X)\n",
    "    print(\"Initial sat level %.5f\" % axioms(sample_X, sample_y))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_dict = {\n",
    "    'train_sat_kb': tf.keras.metrics.Mean(name='train_sat_kb'),\n",
    "    'test_sat_kb': tf.keras.metrics.Mean(name='test_sat_kb'),\n",
    "    'train_accuracy': tf.keras.metrics.CategoricalAccuracy(name=\"train_accuracy\"),\n",
    "    'test_accuracy': tf.keras.metrics.CategoricalAccuracy(name=\"test_accuracy\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(features, labels, optimizer):\n",
    "    # sat and update\n",
    "    with tf.GradientTape() as tape:\n",
    "        sat = axioms(features, labels, training=True)\n",
    "        loss = 1. - sat\n",
    "    gradients = tape.gradient(loss, p.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, p.trainable_variables))\n",
    "    sat = axioms(features, labels)  # compute sat without dropout\n",
    "    metrics_dict['train_sat_kb'](sat)\n",
    "    # accuracy\n",
    "    predictions = model([features])\n",
    "    metrics_dict['train_accuracy'](labels, predictions)\n",
    "\n",
    "@tf.function\n",
    "def test_step(features, labels, optimizer):\n",
    "    # sat\n",
    "    sat = axioms(features, labels)\n",
    "    metrics_dict['test_sat_kb'](sat)\n",
    "    # accuracy\n",
    "    predictions = model([features])\n",
    "    metrics_dict['test_accuracy'](labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: vgf15mnb\n",
      "Sweep URL: https://wandb.ai/dds-paper/dds-paper/sweeps/vgf15mnb\n"
     ]
    }
   ],
   "source": [
    "# Sweep configuration\n",
    "sweep_config = {\n",
    "    \"name\": \"dds-sweep\",\n",
    "    \"method\": \"random\",\n",
    "    \"metric\": {\n",
    "        \"name\": \"test_sat_kb\",\n",
    "        \"goal\": \"maximize\"\n",
    "    },\n",
    "    \"parameters\": {\n",
    "        \"batch_size\": {\n",
    "            \"values\": [32, 64, 128, 256, 1024, 4096]\n",
    "        },\n",
    "        \"epochs\": {\n",
    "            \"values\": [5]\n",
    "        },\n",
    "        \"learning_rate\": {\n",
    "            \"min\": 0.0001,\n",
    "            \"max\": 0.1\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Initialize the sweep\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"dds-paper\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import wandb  # Import wandb\n",
    "\n",
    "def train(epochs, metrics_dict, train_generator_func, test_generator_func, train_step, test_step,\n",
    "          num_train_steps, num_test_steps, track_metrics=1, csv_path=None, scheduled_parameters=defaultdict(lambda: {}), optimizer=None):\n",
    "\n",
    "    if csv_path is not None:\n",
    "        csv_file = open(csv_path, \"w+\")\n",
    "        headers = \",\".join([\"Epoch\"] + list(metrics_dict.keys()))\n",
    "        csv_template = \",\".join([\"{}\" for _ in range(len(metrics_dict) + 1)])\n",
    "        csv_file.write(headers + \"\\n\")\n",
    "\n",
    "    epoch_times = []\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Initialize accumulators for training metrics\n",
    "        total_train_sat_kb = 0\n",
    "        total_train_accuracy = 0\n",
    "        num_train_steps = 0\n",
    "\n",
    "        # Initialize accumulators for validation metrics\n",
    "        total_test_sat_kb = 0\n",
    "        total_test_accuracy = 0\n",
    "        num_test_steps = 0\n",
    "\n",
    "        # Reset metrics\n",
    "        for metrics in metrics_dict.values():\n",
    "            metrics.reset_states()\n",
    "\n",
    "        # Training loop\n",
    "        train_generator = train_generator_func()\n",
    "        pbar = tqdm(total=num_train_steps)\n",
    "        for batch_elements in train_generator:\n",
    "            train_step(*batch_elements, optimizer=optimizer, **scheduled_parameters[epoch])\n",
    "            \n",
    "            # Accumulate training metrics\n",
    "            total_train_sat_kb += metrics_dict['train_sat_kb'].result().numpy()\n",
    "            total_train_accuracy += metrics_dict['train_accuracy'].result().numpy()\n",
    "            num_train_steps += 1\n",
    "\n",
    "            pbar.update()\n",
    "        pbar.close()\n",
    "\n",
    "        # Compute average training metrics for the epoch\n",
    "        avg_train_sat_kb = total_train_sat_kb / num_train_steps\n",
    "        avg_train_accuracy = total_train_accuracy / num_train_steps\n",
    "\n",
    "        # Validation loop\n",
    "        test_generator = test_generator_func()\n",
    "        pbar = tqdm(total=num_test_steps)\n",
    "        for batch_elements in test_generator:\n",
    "            test_step(*batch_elements, optimizer=optimizer, **scheduled_parameters[epoch])\n",
    "\n",
    "            # Accumulate validation metrics\n",
    "            total_test_sat_kb += metrics_dict['test_sat_kb'].result().numpy()\n",
    "            total_test_accuracy += metrics_dict['test_accuracy'].result().numpy()\n",
    "            num_test_steps += 1\n",
    "\n",
    "            pbar.update()\n",
    "        pbar.close()\n",
    "\n",
    "        # Compute average validation metrics for the epoch\n",
    "        avg_test_sat_kb = total_test_sat_kb / num_test_steps\n",
    "        avg_test_accuracy = total_test_accuracy / num_test_steps\n",
    "\n",
    "        # Log the average metrics to Wandb\n",
    "        wandb.log({\n",
    "            'Epoch': epoch,\n",
    "            'Average Train Satisfaction': avg_train_sat_kb,\n",
    "            'Average Train Accuracy': avg_train_accuracy,\n",
    "            'Average Validation Satisfaction': avg_test_sat_kb,\n",
    "            'Average Validation Accuracy': avg_test_accuracy\n",
    "        })\n",
    "\n",
    "        # Additional logging\n",
    "        if csv_path is not None:\n",
    "            metrics_results = [metrics.result() for metrics in metrics_dict.values()]\n",
    "            csv_file.write(csv_template.format(epoch, *metrics_results) + \"\\n\")\n",
    "            csv_file.flush()\n",
    "\n",
    "        end_time = time.time()\n",
    "        epoch_times.append(end_time - start_time)\n",
    "        start_time = end_time\n",
    "\n",
    "    if csv_path is not None:\n",
    "        csv_file.close()\n",
    "\n",
    "    return epoch_times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the learning rate as a tf.Variable so it can be updated\n",
    "learning_rate = tf.Variable(initial_value=0.001, trainable=False, dtype=tf.float32)\n",
    "\n",
    "# Initialize the optimizer with this learning rate variable\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "def train_wrapper():\n",
    "    # Initialize Wandb for this sweep run\n",
    "    run = wandb.init()\n",
    "\n",
    "    # Use hyperparameters from wandb.config\n",
    "    epochs = wandb.config.epochs\n",
    "    batch_size = wandb.config.batch_size\n",
    "    # Update the learning rate using the hyperparameter from wandb.config\n",
    "    learning_rate.assign(wandb.config.learning_rate)\n",
    "\n",
    "    # Rest of your existing setup code\n",
    "    num_train_steps = sum(1 for _ in data_generator(batch_size, data=train_path))\n",
    "    num_test_steps = sum(1 for _ in data_generator(batch_size, data=val_path))\n",
    "\n",
    "    def train_generator_func():\n",
    "        return data_generator_all(batch_size=wandb.config.batch_size, data=train_path)\n",
    "\n",
    "    def val_generator_func():\n",
    "        return data_generator_all(batch_size=wandb.config.batch_size, data=val_path)\n",
    "\n",
    "    # Call your existing train function\n",
    "    epoch_times = train(\n",
    "        wandb.config.epochs,\n",
    "        metrics_dict,\n",
    "        train_generator_func,\n",
    "        val_generator_func,\n",
    "        train_step,\n",
    "        test_step,\n",
    "        csv_path=\"/home/ubuntu/dds_paper/DDS_Paper/data/final.csv\",\n",
    "        track_metrics=1,\n",
    "        num_train_steps=num_train_steps,\n",
    "        num_test_steps=num_test_steps,\n",
    "        optimizer=optimizer \n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<IPython.core.display.HTML object>\n",
      "<IPython.core.display.HTML object>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: th1wn47c with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.01121735911962534\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/dds_paper/DDS_Paper/wandb/run-20230912_071022-th1wn47c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dds-paper/dds-paper/runs/th1wn47c' target=\"_blank\">lunar-sweep-1</a></strong> to <a href='https://wandb.ai/dds-paper/dds-paper' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dds-paper/dds-paper/sweeps/vgf15mnb' target=\"_blank\">https://wandb.ai/dds-paper/dds-paper/sweeps/vgf15mnb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dds-paper/dds-paper' target=\"_blank\">https://wandb.ai/dds-paper/dds-paper</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dds-paper/dds-paper/sweeps/vgf15mnb' target=\"_blank\">https://wandb.ai/dds-paper/dds-paper/sweeps/vgf15mnb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dds-paper/dds-paper/runs/th1wn47c' target=\"_blank\">https://wandb.ai/dds-paper/dds-paper/runs/th1wn47c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread ChkStopThr:\n",
      "Traceback (most recent call last):\n",
      "Exception in thread   File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "IntMsgThrException in thread     :\n",
      "NetStatThrself.run()Traceback (most recent call last):\n",
      ":\n",
      "\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
      "      File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()self._target(*self._args, **self._kwargs)    \n",
      "\n",
      "self.run()  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
      "  File \"/home/ubuntu/dds_paper/DDS_Paper/.venv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 285, in check_stop_status\n",
      "\n",
      "          File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
      "self._target(*self._args, **self._kwargs)self._loop_check_status(\n",
      "    \n",
      "  File \"/home/ubuntu/dds_paper/DDS_Paper/.venv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 299, in check_internal_messages\n",
      "self._target(*self._args, **self._kwargs)  File \"/home/ubuntu/dds_paper/DDS_Paper/.venv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 223, in _loop_check_status\n",
      "    \n",
      "    self._loop_check_status(  File \"/home/ubuntu/dds_paper/DDS_Paper/.venv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 267, in check_network_status\n",
      "local_handle = request()\n",
      "    \n",
      "  File \"/home/ubuntu/dds_paper/DDS_Paper/.venv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 223, in _loop_check_status\n",
      "self._loop_check_status(  File \"/home/ubuntu/dds_paper/DDS_Paper/.venv/lib/python3.10/site-packages/wandb/sdk/interface/interface.py\", line 727, in deliver_stop_status\n",
      "    \n",
      "local_handle = request()      File \"/home/ubuntu/dds_paper/DDS_Paper/.venv/lib/python3.10/site-packages/wandb/sdk/wandb_run.py\", line 223, in _loop_check_status\n",
      "\n",
      "return self._deliver_stop_status(status)      File \"/home/ubuntu/dds_paper/DDS_Paper/.venv/lib/python3.10/site-packages/wandb/sdk/interface/interface.py\", line 743, in deliver_internal_messages\n",
      "\n",
      "local_handle = request()      File \"/home/ubuntu/dds_paper/DDS_Paper/.venv/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py\", line 450, in _deliver_stop_status\n",
      "\n",
      "return self._deliver_internal_messages(internal_message)      File \"/home/ubuntu/dds_paper/DDS_Paper/.venv/lib/python3.10/site-packages/wandb/sdk/interface/interface.py\", line 735, in deliver_network_status\n",
      "\n",
      "return self._deliver_record(record)      File \"/home/ubuntu/dds_paper/DDS_Paper/.venv/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py\", line 472, in _deliver_internal_messages\n",
      "\n",
      "return self._deliver_network_status(status)  File \"/home/ubuntu/dds_paper/DDS_Paper/.venv/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py\", line 425, in _deliver_record\n",
      "    \n",
      "    return self._deliver_record(record)  File \"/home/ubuntu/dds_paper/DDS_Paper/.venv/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py\", line 466, in _deliver_network_status\n",
      "handle = mailbox._deliver_record(record, interface=self)\n",
      "    \n",
      "  File \"/home/ubuntu/dds_paper/DDS_Paper/.venv/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py\", line 425, in _deliver_record\n",
      "return self._deliver_record(record)  File \"/home/ubuntu/dds_paper/DDS_Paper/.venv/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py\", line 455, in _deliver_record\n",
      "    \n",
      "handle = mailbox._deliver_record(record, interface=self)  File \"/home/ubuntu/dds_paper/DDS_Paper/.venv/lib/python3.10/site-packages/wandb/sdk/interface/interface_shared.py\", line 425, in _deliver_record\n",
      "    \n",
      "    interface._publish(record)  File \"/home/ubuntu/dds_paper/DDS_Paper/.venv/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py\", line 455, in _deliver_record\n",
      "handle = mailbox._deliver_record(record, interface=self)\n",
      "    \n",
      "  File \"/home/ubuntu/dds_paper/DDS_Paper/.venv/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n",
      "interface._publish(record)  File \"/home/ubuntu/dds_paper/DDS_Paper/.venv/lib/python3.10/site-packages/wandb/sdk/lib/mailbox.py\", line 455, in _deliver_record\n",
      "    \n",
      "self._sock_client.send_record_publish(record)      File \"/home/ubuntu/dds_paper/DDS_Paper/.venv/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n",
      "\n",
      "interface._publish(record)  File \"/home/ubuntu/dds_paper/DDS_Paper/.venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n",
      "    \n",
      "self._sock_client.send_record_publish(record)      File \"/home/ubuntu/dds_paper/DDS_Paper/.venv/lib/python3.10/site-packages/wandb/sdk/interface/interface_sock.py\", line 51, in _publish\n",
      "\n",
      "self.send_server_request(server_req)      File \"/home/ubuntu/dds_paper/DDS_Paper/.venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n",
      "\n",
      "self._sock_client.send_record_publish(record)  File \"/home/ubuntu/dds_paper/DDS_Paper/.venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
      "    \n",
      "self.send_server_request(server_req)      File \"/home/ubuntu/dds_paper/DDS_Paper/.venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 221, in send_record_publish\n",
      "\n",
      "self._send_message(msg)      File \"/home/ubuntu/dds_paper/DDS_Paper/.venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
      "\n",
      "self.send_server_request(server_req)  File \"/home/ubuntu/dds_paper/DDS_Paper/.venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
      "\n",
      "          File \"/home/ubuntu/dds_paper/DDS_Paper/.venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 155, in send_server_request\n",
      "self._send_message(msg)self._sendall_with_error_handle(header + data)    \n",
      "\n",
      "self._send_message(msg)  File \"/home/ubuntu/dds_paper/DDS_Paper/.venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
      "  File \"/home/ubuntu/dds_paper/DDS_Paper/.venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "\n",
      "          File \"/home/ubuntu/dds_paper/DDS_Paper/.venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 152, in _send_message\n",
      "self._sendall_with_error_handle(header + data)sent = self._sock.send(data)    \n",
      "\n",
      "self._sendall_with_error_handle(header + data)  File \"/home/ubuntu/dds_paper/DDS_Paper/.venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "BrokenPipeError\n",
      "    :   File \"/home/ubuntu/dds_paper/DDS_Paper/.venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "sent = self._sock.send(data)[Errno 32] Broken pipe    \n",
      "\n",
      "sent = self._sock.send(data)BrokenPipeError\n",
      ": BrokenPipeError[Errno 32] Broken pipe: \n",
      "[Errno 32] Broken pipe\n",
      "22708it [17:14, 21.95it/s]\n",
      "5677it [01:32, 61.70it/s]\n",
      "22708it [16:53, 22.42it/s]\n",
      "5677it [01:23, 67.82it/s]\n",
      "22708it [16:42, 22.64it/s]\n",
      "5677it [01:24, 66.93it/s]\n",
      "22708it [16:37, 22.77it/s]\n",
      "5677it [01:22, 68.75it/s]\n",
      "22708it [16:54, 22.38it/s]\n",
      "5677it [01:23, 67.77it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Average Train Accuracy</td><td>▆▂▁▅█</td></tr><tr><td>Average Train Satisfaction</td><td>▁▇███</td></tr><tr><td>Average Validation Accuracy</td><td>▁▅▇█▃</td></tr><tr><td>Average Validation Satisfaction</td><td>▁▅▇█▇</td></tr><tr><td>Epoch</td><td>▁▃▅▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Average Train Accuracy</td><td>0.0698</td></tr><tr><td>Average Train Satisfaction</td><td>0.69892</td></tr><tr><td>Average Validation Accuracy</td><td>0.06945</td></tr><tr><td>Average Validation Satisfaction</td><td>0.69873</td></tr><tr><td>Epoch</td><td>4</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">lunar-sweep-1</strong> at: <a href='https://wandb.ai/dds-paper/dds-paper/runs/th1wn47c' target=\"_blank\">https://wandb.ai/dds-paper/dds-paper/runs/th1wn47c</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230912_071022-th1wn47c/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 55ofupj1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 256\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.002452186804581092\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/dds_paper/DDS_Paper/wandb/run-20230912_084317-55ofupj1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dds-paper/dds-paper/runs/55ofupj1' target=\"_blank\">sweepy-sweep-2</a></strong> to <a href='https://wandb.ai/dds-paper/dds-paper' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dds-paper/dds-paper/sweeps/vgf15mnb' target=\"_blank\">https://wandb.ai/dds-paper/dds-paper/sweeps/vgf15mnb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dds-paper/dds-paper' target=\"_blank\">https://wandb.ai/dds-paper/dds-paper</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dds-paper/dds-paper/sweeps/vgf15mnb' target=\"_blank\">https://wandb.ai/dds-paper/dds-paper/sweeps/vgf15mnb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dds-paper/dds-paper/runs/55ofupj1' target=\"_blank\">https://wandb.ai/dds-paper/dds-paper/runs/55ofupj1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22708it [16:58, 22.29it/s]\n",
      "5677it [01:25, 66.71it/s]\n",
      "22708it [16:38, 22.73it/s]\n",
      "5677it [01:24, 66.91it/s]\n",
      "22708it [17:04, 22.16it/s]\n",
      "5677it [01:23, 68.09it/s]\n",
      "22708it [16:39, 22.71it/s]\n",
      "5677it [01:22, 68.45it/s]\n",
      "22708it [16:35, 22.81it/s]\n",
      "5677it [01:25, 66.68it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Average Train Accuracy</td><td>▆▇█▅▁</td></tr><tr><td>Average Train Satisfaction</td><td>▁▃▅▇█</td></tr><tr><td>Average Validation Accuracy</td><td>▅▅█▁▇</td></tr><tr><td>Average Validation Satisfaction</td><td>▄▆█▁▇</td></tr><tr><td>Epoch</td><td>▁▃▅▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Average Train Accuracy</td><td>0.06806</td></tr><tr><td>Average Train Satisfaction</td><td>0.69935</td></tr><tr><td>Average Validation Accuracy</td><td>0.07109</td></tr><tr><td>Average Validation Satisfaction</td><td>0.69916</td></tr><tr><td>Epoch</td><td>4</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">sweepy-sweep-2</strong> at: <a href='https://wandb.ai/dds-paper/dds-paper/runs/55ofupj1' target=\"_blank\">https://wandb.ai/dds-paper/dds-paper/runs/55ofupj1</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230912_084317-55ofupj1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tdp3273a with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4096\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.05717383084420348\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/dds_paper/DDS_Paper/wandb/run-20230912_101546-tdp3273a</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dds-paper/dds-paper/runs/tdp3273a' target=\"_blank\">upbeat-sweep-3</a></strong> to <a href='https://wandb.ai/dds-paper/dds-paper' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dds-paper/dds-paper/sweeps/vgf15mnb' target=\"_blank\">https://wandb.ai/dds-paper/dds-paper/sweeps/vgf15mnb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dds-paper/dds-paper' target=\"_blank\">https://wandb.ai/dds-paper/dds-paper</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dds-paper/dds-paper/sweeps/vgf15mnb' target=\"_blank\">https://wandb.ai/dds-paper/dds-paper/sweeps/vgf15mnb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dds-paper/dds-paper/runs/tdp3273a' target=\"_blank\">https://wandb.ai/dds-paper/dds-paper/runs/tdp3273a</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1419it [05:51,  4.03it/s]\n",
      "354it [00:27, 12.90it/s]\n",
      "1419it [05:09,  4.58it/s]\n",
      "354it [00:21, 16.81it/s]\n",
      "1419it [05:02,  4.70it/s]\n",
      "354it [00:21, 16.69it/s]\n",
      "1419it [04:55,  4.81it/s]\n",
      "354it [00:21, 16.57it/s]\n",
      "1419it [04:45,  4.97it/s]\n",
      "354it [00:20, 17.58it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Average Train Accuracy</td><td>▃▇█▁▅</td></tr><tr><td>Average Train Satisfaction</td><td>▁▆▆▅█</td></tr><tr><td>Average Validation Accuracy</td><td>▁▁██▃</td></tr><tr><td>Average Validation Satisfaction</td><td>▅▁▂▃█</td></tr><tr><td>Epoch</td><td>▁▃▅▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Average Train Accuracy</td><td>0.07073</td></tr><tr><td>Average Train Satisfaction</td><td>0.69972</td></tr><tr><td>Average Validation Accuracy</td><td>0.07045</td></tr><tr><td>Average Validation Satisfaction</td><td>0.69963</td></tr><tr><td>Epoch</td><td>4</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">upbeat-sweep-3</strong> at: <a href='https://wandb.ai/dds-paper/dds-paper/runs/tdp3273a' target=\"_blank\">https://wandb.ai/dds-paper/dds-paper/runs/tdp3273a</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230912_101546-tdp3273a/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jo3h07tx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 1024\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0736219886652007\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/dds_paper/DDS_Paper/wandb/run-20230912_104353-jo3h07tx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dds-paper/dds-paper/runs/jo3h07tx' target=\"_blank\">laced-sweep-4</a></strong> to <a href='https://wandb.ai/dds-paper/dds-paper' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dds-paper/dds-paper/sweeps/vgf15mnb' target=\"_blank\">https://wandb.ai/dds-paper/dds-paper/sweeps/vgf15mnb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dds-paper/dds-paper' target=\"_blank\">https://wandb.ai/dds-paper/dds-paper</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dds-paper/dds-paper/sweeps/vgf15mnb' target=\"_blank\">https://wandb.ai/dds-paper/dds-paper/sweeps/vgf15mnb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dds-paper/dds-paper/runs/jo3h07tx' target=\"_blank\">https://wandb.ai/dds-paper/dds-paper/runs/jo3h07tx</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5677it [07:39, 12.36it/s]\n",
      "1419it [00:44, 31.74it/s]\n",
      "5677it [07:05, 13.35it/s]\n",
      "1419it [00:38, 36.52it/s]\n",
      "5677it [06:51, 13.80it/s]\n",
      "1419it [00:37, 37.84it/s]\n",
      "5677it [07:04, 13.38it/s]\n",
      "1419it [00:38, 36.93it/s]\n",
      "5677it [06:58, 13.57it/s]\n",
      "1419it [00:37, 38.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Average Train Accuracy</td><td>▆▄▆█▁</td></tr><tr><td>Average Train Satisfaction</td><td>▁▄▇▆█</td></tr><tr><td>Average Validation Accuracy</td><td>▅▁▆█▃</td></tr><tr><td>Average Validation Satisfaction</td><td>▆▁█▆▄</td></tr><tr><td>Epoch</td><td>▁▃▅▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Average Train Accuracy</td><td>0.06828</td></tr><tr><td>Average Train Satisfaction</td><td>0.69967</td></tr><tr><td>Average Validation Accuracy</td><td>0.06706</td></tr><tr><td>Average Validation Satisfaction</td><td>0.69955</td></tr><tr><td>Epoch</td><td>4</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">laced-sweep-4</strong> at: <a href='https://wandb.ai/dds-paper/dds-paper/runs/jo3h07tx' target=\"_blank\">https://wandb.ai/dds-paper/dds-paper/runs/jo3h07tx</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230912_104353-jo3h07tx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 34tugnuk with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4096\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.07354115863536996\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/dds_paper/DDS_Paper/wandb/run-20230912_112328-34tugnuk</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dds-paper/dds-paper/runs/34tugnuk' target=\"_blank\">ruby-sweep-5</a></strong> to <a href='https://wandb.ai/dds-paper/dds-paper' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dds-paper/dds-paper/sweeps/vgf15mnb' target=\"_blank\">https://wandb.ai/dds-paper/dds-paper/sweeps/vgf15mnb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dds-paper/dds-paper' target=\"_blank\">https://wandb.ai/dds-paper/dds-paper</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dds-paper/dds-paper/sweeps/vgf15mnb' target=\"_blank\">https://wandb.ai/dds-paper/dds-paper/sweeps/vgf15mnb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dds-paper/dds-paper/runs/34tugnuk' target=\"_blank\">https://wandb.ai/dds-paper/dds-paper/runs/34tugnuk</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1419it [04:56,  4.78it/s]\n",
      "354it [00:21, 16.65it/s]\n",
      "1419it [05:02,  4.68it/s]\n",
      "354it [00:20, 17.34it/s]\n",
      "1419it [05:00,  4.73it/s]\n",
      "354it [00:21, 16.52it/s]\n",
      "1419it [04:44,  4.99it/s]\n",
      "354it [00:21, 16.58it/s]\n",
      "1419it [04:46,  4.95it/s]\n",
      "354it [00:21, 16.30it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Average Train Accuracy</td><td>▄▁█▃▆</td></tr><tr><td>Average Train Satisfaction</td><td>▂▆▂▁█</td></tr><tr><td>Average Validation Accuracy</td><td>▃▁█▄▇</td></tr><tr><td>Average Validation Satisfaction</td><td>▆▁▃▄█</td></tr><tr><td>Epoch</td><td>▁▃▅▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Average Train Accuracy</td><td>0.07143</td></tr><tr><td>Average Train Satisfaction</td><td>0.69983</td></tr><tr><td>Average Validation Accuracy</td><td>0.07286</td></tr><tr><td>Average Validation Satisfaction</td><td>0.69975</td></tr><tr><td>Epoch</td><td>4</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ruby-sweep-5</strong> at: <a href='https://wandb.ai/dds-paper/dds-paper/runs/34tugnuk' target=\"_blank\">https://wandb.ai/dds-paper/dds-paper/runs/34tugnuk</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230912_112328-34tugnuk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ci9n43ie with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4096\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.058755322611721304\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/dds_paper/DDS_Paper/wandb/run-20230912_115012-ci9n43ie</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dds-paper/dds-paper/runs/ci9n43ie' target=\"_blank\">spring-sweep-6</a></strong> to <a href='https://wandb.ai/dds-paper/dds-paper' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dds-paper/dds-paper/sweeps/vgf15mnb' target=\"_blank\">https://wandb.ai/dds-paper/dds-paper/sweeps/vgf15mnb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dds-paper/dds-paper' target=\"_blank\">https://wandb.ai/dds-paper/dds-paper</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dds-paper/dds-paper/sweeps/vgf15mnb' target=\"_blank\">https://wandb.ai/dds-paper/dds-paper/sweeps/vgf15mnb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dds-paper/dds-paper/runs/ci9n43ie' target=\"_blank\">https://wandb.ai/dds-paper/dds-paper/runs/ci9n43ie</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1419it [04:48,  4.92it/s]\n",
      "354it [00:20, 17.12it/s]\n",
      "1419it [04:55,  4.81it/s]\n",
      "354it [00:21, 16.34it/s]\n",
      "1419it [04:50,  4.88it/s]\n",
      "354it [00:21, 16.74it/s]\n",
      "1419it [05:07,  4.61it/s]\n",
      "354it [00:21, 16.40it/s]\n",
      "1419it [04:57,  4.77it/s]\n",
      "354it [00:21, 16.21it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Average Train Accuracy</td><td>█▅▁▆▁</td></tr><tr><td>Average Train Satisfaction</td><td>▃▁▆▅█</td></tr><tr><td>Average Validation Accuracy</td><td>▃▁▁▂█</td></tr><tr><td>Average Validation Satisfaction</td><td>▆▁█▆▇</td></tr><tr><td>Epoch</td><td>▁▃▅▆█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Average Train Accuracy</td><td>0.06587</td></tr><tr><td>Average Train Satisfaction</td><td>0.69983</td></tr><tr><td>Average Validation Accuracy</td><td>0.07414</td></tr><tr><td>Average Validation Satisfaction</td><td>0.6998</td></tr><tr><td>Epoch</td><td>4</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">spring-sweep-6</strong> at: <a href='https://wandb.ai/dds-paper/dds-paper/runs/ci9n43ie' target=\"_blank\">https://wandb.ai/dds-paper/dds-paper/runs/ci9n43ie</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230912_115012-ci9n43ie/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 8l0zbzee with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.005365382870852202\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/ubuntu/dds_paper/DDS_Paper/wandb/run-20230912_121714-8l0zbzee</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dds-paper/dds-paper/runs/8l0zbzee' target=\"_blank\">valiant-sweep-7</a></strong> to <a href='https://wandb.ai/dds-paper/dds-paper' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/dds-paper/dds-paper/sweeps/vgf15mnb' target=\"_blank\">https://wandb.ai/dds-paper/dds-paper/sweeps/vgf15mnb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dds-paper/dds-paper' target=\"_blank\">https://wandb.ai/dds-paper/dds-paper</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/dds-paper/dds-paper/sweeps/vgf15mnb' target=\"_blank\">https://wandb.ai/dds-paper/dds-paper/sweeps/vgf15mnb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dds-paper/dds-paper/runs/8l0zbzee' target=\"_blank\">https://wandb.ai/dds-paper/dds-paper/runs/8l0zbzee</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45416it [22:49, 33.16it/s]\n",
      "11354it [02:20, 80.69it/s]\n",
      "45416it [21:47, 34.73it/s]\n",
      "11354it [02:10, 86.87it/s]\n",
      "45416it [21:38, 34.96it/s]\n",
      "11354it [02:11, 86.30it/s] \n",
      "45416it [21:47, 34.73it/s]\n",
      "11354it [02:12, 85.58it/s]\n",
      "38448it [18:36, 25.87it/s]"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, function=train_wrapper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 256\n",
    "\n",
    "# EPOCHS = 5\n",
    "\n",
    "# # Get the number of training and testing steps per epoch\n",
    "# num_train_steps = sum(1 for _ in data_generator(batch_size, data='train.csv'))\n",
    "# num_test_steps = sum(1 for _ in data_generator(batch_size, data='val.csv'))\n",
    "\n",
    "# optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "# # Define your generator functions\n",
    "# def train_generator_func():\n",
    "#     return data_generator_all(batch_size=batch_size, data='train.csv')\n",
    "\n",
    "# def val_generator_func():\n",
    "#     return data_generator_all(batch_size=batch_size, data='val.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# training = train(\n",
    "#     EPOCHS,\n",
    "#     metrics_dict,\n",
    "#     train_generator_func,\n",
    "#     val_generator_func,\n",
    "#     train_step,\n",
    "#     test_step,\n",
    "#     csv_path=\"final.csv\",\n",
    "#     track_metrics=1,\n",
    "#     num_train_steps=num_train_steps,\n",
    "#     num_test_steps=num_test_steps\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work_stable",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
